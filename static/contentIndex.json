{"content/Projects/JEngine---DX12/DirectX12/엔진-개발-01---프로젝트-초기-설정":{"slug":"content/Projects/JEngine---DX12/DirectX12/엔진-개발-01---프로젝트-초기-설정","filePath":"content/Projects/JEngine - DX12/DirectX12/엔진 개발 01 - 프로젝트 초기 설정.md","title":"엔진 개발 01 - 프로젝트 초기 설정","links":[],"tags":["VS2022","Project","Git"],"content":"프로젝트 생성\n\n\n엔진 프로젝트를 시작하기 하기 위해 Git과 VS2022 설정을 해줬습니다.\n\n\n\n\n\n규모가 작은 아주 간단한 계산기 같은 프로젝트면 상관없겠지만 렌더러와 같은 클래스가 많아지고 기능이 이것저것 많이 들어가는 경우 Project를 여러개 만들어서 Dependency를 설정해주는 것이 코드를 정리하기 더 좋은 것 같습니다.\n\n\n추가적으로 클래스가 많아지면 기능별로 클래스를 따로 폴더별로 묶어서 분류하는게 관리하기 종하집니다.\n\nApplication과 Engine Project의 설정창\n\n\n\n\n일단 Application, Asset, Engine 3개의 프로젝트를 만들어줬습니다.\n\n\n여기서 Application과 Asset은 그냥 Empty Project로 아무것도 없이 만들었고 Engine은 이번 프로젝트의 Core 부분으로 Static Library로 프로젝트를 생성했습니다.\n\nAsset은 프로젝트로 만들어주긴 했는데 굳이 만들어주지 않아도 될 것 같고 따로 폴더만 만들어도 됩니다.\n\n\n\n여기서는 Texture, Shader 등의 Asset들을 따로 보기 편하게 하기 위해서 빈 프로젝트로 묶어서 Visual Studio에서 보기 편하려고 한 것입니다.\n\n\n\nProject Dependency 설정\nProject의 Dependency를 설정해서 나중에 Application Project에서 Engine Project를 #include를 사용해서 편하게 가져올 수 있게 해줬습니다.\n\n물론 두 번째 이미지처럼 Engine Project는 static library이므로 build하고 나온 .lib 파일을 가져다가 직접 Link시켜서 사용할 수 있지만 위의 방법이 더 편리합니다.\n\n\n\n\n\nFormatter\n\n\n.clang-format 파일을 프로젝트를 생성한 위치에 배치해서 간단하게 formatter를 적용시켰습니다.\n\n이건 코드가 많아져도 일관적인 Format을 유지할 수 있게 해줍니다.\n\n\n\n---\nBasedOnStyle: LLVM\nIndentWidth: 4\nTabWidth: 4\nUseTab: Never\nColumnLimit: 100\n \nLanguage: Cpp\nStandard: c++20\n \nAllowShortBlocksOnASingleLine: false\nAllowShortIfStatementsOnASingleLine: false\nAllowShortLoopsOnASingleLine: false\nAllowShortFunctionsOnASingleLine: false\nAlwaysBreakTemplateDeclarations: Yes\nAlignTrailingComments: true\n \nBreakBeforeBraces: Custom\nBraceWrapping:\n    AfterFunction: false\n    AfterClass: true\n    AfterControlStatement: Never\n    AfterEnum: false\n    AfterNamespace: false\n    AfterStruct: true\n    BeforeCatch: false\n    BeforeElse: false\n \n# Multiplatform compatibility settings\nIncludeBlocks: Preserve\nSortIncludes: false\nFixNamespaceComments: true\nCompactNamespaces: false\nPointerAlignment: Left\nReferenceAlignment: Pointer\nAccessModifierOffset: -2\nDeriveLineEnding: false\nUseCRLF: false\nGit 설정\n\n\nGit 설정 파일들\n.gitattributes 파일의 경우 지금 나는 사용할 필요가 없지만 강의에서 배웠던 것처럼 OS마다 Text 파일의 Format이 다르기 때문에 다른 OS에서 프로젝트를 실행하는 경우응 위해 만든 파일로 GPT를 사용해서 만들었다고 하며 이렇게 프로젝트 위치에 배치해두면 됩니다.\n\n# Ensure consistent line endings across platforms\n* text=auto eol=lf\n \n# Specific file types\n*.cpp text eol=lf\n*.h text eol=lf\n*.hpp text eol=lf\n*.c text eol=lf\n*.cmake text eol=lf\n*.txt text eol=lf\n*.md text eol=lf\n*.json text eol=lf\n*.yml text eol=lf\n*.yaml text eol=lf\n \n# Shell scripts must use LF\n*.sh text eol=lf\n \n# Windows-specific files can use CRLF\n*.bat text eol=crlf\n*.cmd text eol=crlf\n \n# Binary files\n*.png binary\n*.jpg binary\n*.spv binary\n*.ktx2 binary\n \n# Additional C++ related files\n*.cc text eol=lf\n*.cxx text eol=lf\n*.inl text eol=lf\n*.inc text eol=lf\n \n# Build system files\n*.vcxproj text eol=crlf\n*.vcxproj.filters text eol=crlf\n*.vcxproj.user text eol=crlf\n*.sln text eol=crlf\nMakefile text eol=lf\n \n# Shader files\n*.vert text eol=lf\n*.frag text eol=lf\n*.glsl text eol=lf\n*.hlsl text eol=lf\n \n# Additional binary types\n*.exe binary\n*.dll binary\n*.so binary\n*.dylib binary\n*.lib binary\n*.a binary\n*.obj binary\n*.o binary\n*.pdb binary\n\n.gitignore 파일의 경우 Github에 올라가면 안되는 중요한 데이터를 포함한 파일이나 쓸모없는 파일, 너무 큰 파일등을 올리면 좋지 않기 때문에 이런 파일이나 폴더를 제외할 때 설정하는 파일입니다.\n\n## Ignore Visual Studio temporary files, build results, and\n## files generated by popular Visual Studio add-ons.\n##\n## Get latest from github.com/github/gitignore/blob/main/VisualStudio.gitignore\n \nLibraries/\nvcpkg_installed/\nbuild/\nassets/characters\nassets/models\nassets/Noto_Sans_KR\nassets/textures\n**/imgui.ini\n \n# User-specific files\n*.rsuser\n*.suo\n*.user\n*.userosscache\n*.sln.docstates\n*.env\n \n# User-specific files (MonoDevelop/Xamarin Studio)\n*.userprefs\n \n# Mono auto generated files\nmono_crash.*\n \n# Build results\n[Dd]ebug/\n[Dd]ebugPublic/\n[Rr]elease/\n[Rr]eleases/\nx64/\nx86/\n[Ww][Ii][Nn]32/\n[Aa][Rr][Mm]/\n[Aa][Rr][Mm]64/\n[Aa][Rr][Mm]64[Ee][Cc]/\nbld/\n[Oo]bj/\n[Oo]ut/\n[Ll]og/\n[Ll]ogs/\n \n# Build results on &#039;Bin&#039; directories\n**/[Bb]in/*\n# Uncomment if you have tasks that rely on *.refresh files to move binaries\n# (github.com/github/gitignore/pull/3736)\n#!**/[Bb]in/*.refresh\n \n# Visual Studio 2015/2017 cache/options directory\n.vs/\n# Uncomment if you have tasks that create the project&#039;s static files in wwwroot\n#wwwroot/\n \n# Visual Studio 2017 auto generated files\nGenerated\\ Files/\n \n# MSTest test Results\n[Tt]est[Rr]esult*/\n[Bb]uild[Ll]og.*\n*.trx\n \n# NUnit\n*.VisualState.xml\nTestResult.xml\nnunit-*.xml\n \n# Approval Tests result files\n*.received.*\n \n# Build Results of an ATL Project\n[Dd]ebugPS/\n[Rr]eleasePS/\ndlldata.c\n \n# Benchmark Results\nBenchmarkDotNet.Artifacts/\n \n# .NET Core\nproject.lock.json\nproject.fragment.lock.json\nartifacts/\n \n# ASP.NET Scaffolding\nScaffoldingReadMe.txt\n \n# StyleCop\nStyleCopReport.xml\n \n# Files built by Visual Studio\n*_i.c\n*_p.c\n*_h.h\n*.ilk\n*.meta\n*.obj\n*.idb\n*.iobj\n*.pch\n*.pdb\n*.ipdb\n*.pgc\n*.pgd\n*.rsp\n# but not Directory.Build.rsp, as it configures directory-level build defaults\n!Directory.Build.rsp\n*.sbr\n*.tlb\n*.tli\n*.tlh\n*.tmp\n*.tmp_proj\n*_wpftmp.csproj\n*.log\n*.tlog\n*.vspscc\n*.vssscc\n.builds\n*.pidb\n*.svclog\n*.scc\n \n# Chutzpah Test files\n_Chutzpah*\n \n# Visual C++ cache files\nipch/\n*.aps\n*.ncb\n*.opendb\n*.opensdf\n*.sdf\n*.cachefile\n*.VC.db\n*.VC.VC.opendb\n \n# Visual Studio profiler\n*.psess\n*.vsp\n*.vspx\n*.sap\n \n# Visual Studio Trace Files\n*.e2e\n \n# TFS 2012 Local Workspace\n$tf/\n \n# Guidance Automation Toolkit\n*.gpState\n \n# ReSharper is a .NET coding add-in\n_ReSharper*/\n*.[Rr]e[Ss]harper\n*.DotSettings.user\n \n# TeamCity is a build add-in\n_TeamCity*\n \n# DotCover is a Code Coverage Tool\n*.dotCover\n \n# AxoCover is a Code Coverage Tool\n.axoCover/*\n!.axoCover/settings.json\n \n# Coverlet is a free, cross platform Code Coverage Tool\ncoverage*.json\ncoverage*.xml\ncoverage*.info\n \n# Visual Studio code coverage results\n*.coverage\n*.coveragexml\n \n# NCrunch\n_NCrunch_*\n.NCrunch_*\n.*crunch*.local.xml\nnCrunchTemp_*\n \n# MightyMoose\n*.mm.*\nAutoTest.Net/\n \n# Web workbench (sass)\n.sass-cache/\n \n# Installshield output folder\n[Ee]xpress/\n \n# DocProject is a documentation generator add-in\nDocProject/buildhelp/\nDocProject/Help/*.HxT\nDocProject/Help/*.HxC\nDocProject/Help/*.hhc\nDocProject/Help/*.hhk\nDocProject/Help/*.hhp\nDocProject/Help/Html2\nDocProject/Help/html\n \n# Click-Once directory\npublish/\n \n# Publish Web Output\n*.[Pp]ublish.xml\n*.azurePubxml\n# Note: Comment the next line if you want to checkin your web deploy settings,\n# but database connection strings (with potential passwords) will be unencrypted\n*.pubxml\n*.publishproj\n \n# Microsoft Azure Web App publish settings. Comment the next line if you want to\n# checkin your Azure Web App publish settings, but sensitive information contained\n# in these scripts will be unencrypted\nPublishScripts/\n \n# NuGet Packages\n*.nupkg\n# NuGet Symbol Packages\n*.snupkg\n# The packages folder can be ignored because of Package Restore\n**/[Pp]ackages/*\n# except build/, which is used as an MSBuild target.\n!**/[Pp]ackages/build/\n# Uncomment if necessary however generally it will be regenerated when needed\n#!**/[Pp]ackages/repositories.config\n# NuGet v3&#039;s project.json files produces more ignorable files\n*.nuget.props\n*.nuget.targets\n \n# Microsoft Azure Build Output\ncsx/\n*.build.csdef\n \n# Microsoft Azure Emulator\necf/\nrcf/\n \n# Windows Store app package directories and files\nAppPackages/\nBundleArtifacts/\nPackage.StoreAssociation.xml\n_pkginfo.txt\n*.appx\n*.appxbundle\n*.appxupload\n \n# Visual Studio cache files\n# files ending in .cache can be ignored\n*.[Cc]ache\n# but keep track of directories ending in .cache\n!?*.[Cc]ache/\n \n# Others\nClientBin/\n~$*\n*~\n*.dbmdl\n*.dbproj.schemaview\n*.jfm\n*.pfx\n*.publishsettings\norleans.codegen.cs\n \n# Including strong name files can present a security risk\n# (github.com/github/gitignore/pull/2483#issue-259490424)\n#*.snk\n \n# Since there are multiple workflows, uncomment next line to ignore bower_components\n# (github.com/github/gitignore/pull/1529#issuecomment-104372622)\n#bower_components/\n \n# RIA/Silverlight projects\nGenerated_Code/\n \n# Backup &amp; report files from converting an old project file\n# to a newer Visual Studio version. Backup files are not needed,\n# because we have git ;-)\n_UpgradeReport_Files/\nBackup*/\nUpgradeLog*.XML\nUpgradeLog*.htm\nServiceFabricBackup/\n*.rptproj.bak\n \n# SQL Server files\n*.mdf\n*.ldf\n*.ndf\n \n# Business Intelligence projects\n*.rdl.data\n*.bim.layout\n*.bim_*.settings\n*.rptproj.rsuser\n*- [Bb]ackup.rdl\n*- [Bb]ackup ([0-9]).rdl\n*- [Bb]ackup ([0-9][0-9]).rdl\n \n# Microsoft Fakes\nFakesAssemblies/\n \n# GhostDoc plugin setting file\n*.GhostDoc.xml\n \n# Node.js Tools for Visual Studio\n.ntvs_analysis.dat\nnode_modules/\n \n# Visual Studio 6 build log\n*.plg\n \n# Visual Studio 6 workspace options file\n*.opt\n \n# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)\n*.vbw\n \n# Visual Studio 6 auto-generated project file (contains which files were open etc.)\n*.vbp\n \n# Visual Studio 6 workspace and project file (working project files containing files to include in project)\n*.dsw\n*.dsp\n \n# Visual Studio 6 technical files\n*.ncb\n*.aps\n \n# Visual Studio LightSwitch build output\n**/*.HTMLClient/GeneratedArtifacts\n**/*.DesktopClient/GeneratedArtifacts\n**/*.DesktopClient/ModelManifest.xml\n**/*.Server/GeneratedArtifacts\n**/*.Server/ModelManifest.xml\n_Pvt_Extensions\n \n# Paket dependency manager\n**/.paket/paket.exe\npaket-files/\n \n# FAKE - F# Make\n**/.fake/\n \n# CodeRush personal settings\n**/.cr/personal\n \n# Python Tools for Visual Studio (PTVS)\n**/__pycache__/\n*.pyc\n \n# Cake - Uncomment if you are using it\n#tools/**\n#!tools/packages.config\n \n# Tabs Studio\n*.tss\n \n# Telerik&#039;s JustMock configuration file\n*.jmconfig\n \n# BizTalk build output\n*.btp.cs\n*.btm.cs\n*.odx.cs\n*.xsd.cs\n \n# OpenCover UI analysis results\nOpenCover/\n \n# Azure Stream Analytics local run output\nASALocalRun/\n \n# MSBuild Binary and Structured Log\n*.binlog\nMSBuild_Logs/\n \n# AWS SAM Build and Temporary Artifacts folder\n.aws-sam\n \n# NVidia Nsight GPU debugger configuration file\n*.nvuser\n \n# MFractors (Xamarin productivity tool) working folder\n**/.mfractor/\n \n# Local History for Visual Studio\n**/.localhistory/\n \n# Visual Studio History (VSHistory) files\n.vshistory/\n \n# BeatPulse healthcheck temp database\nhealthchecksdb\n \n# Backup folder for Package Reference Convert tool in Visual Studio 2017\nMigrationBackup/\n \n# Ionide (cross platform F# VS Code tools) working folder\n**/.ionide/\n \n# Fody - auto-generated XML schema\nFodyWeavers.xsd\n \n# VS Code files for those working on multiple tools\n.vscode/*\n!.vscode/settings.json\n!.vscode/tasks.json\n!.vscode/launch.json\n!.vscode/extensions.json\n!.vscode/*.code-snippets\n \n# Local History for Visual Studio Code\n.history/\n \n# Built Visual Studio Code Extensions\n*.vsix\n \n# Windows Installer files from build outputs\n*.cab\n*.msi\n*.msix\n*.msm\n*.msp\n \n\n\n.gitignore은 인터넷에서 유명한 설정파일을 찾아볼 수 있고 GPT를 사용해도 쉽게 만들어줄 수 있습니다.\n\n\n\n\n\nGithub 페이지\n\n이걸 Github에 올려서 프로젝트를 공유하고 Issue, Branch 등을 관리할 예정입니다.\ngithub.com/Jin-SukKim/JEngine\n\n\n\nvcpkg\n\n\n프로젝트를 진행하는데 필요한 외부 Library를 vcpkg를 이용하면 vs2022에서 쉽게 사용할 수 있습니다. C++의 경우 외부 라이브러리를 가져와 사용하려면 Library를 직접 다운받은 다음에 폴더 경로를 VS2022에 설정하고 Link를 해줘야 합니다. 이런 과정은 매우 번거롭고 Link하는데 실수로 오류도 많이 생깁니다. 하지만 vcpkg를 사용하면 python의 pip install처럼 쉽게 사용할 수 있습니다.\n\nTutorial: Package a library with vcpkg | Microsoft Learn\nGitHub - microsoft/vcpkg: C++ Library Manager for Windows, Linux, and MacOS\n\n\n\nvcpkg를 다운받은 다음에 컴퓨터의 Environment Path에서 경로를 설정해주면 좀 더 쉽게 사용할 수 있지만 아니라면 vcpkg를 다운받은 폴더 위치에서 command 창을 이용해서 vcpkg를 사용할 수 있습니다.\n\n\nvcpkg search library // 원하는 library가 있는지 확인\nvcpkg install library // 원하는 라이브러리 설치\nvcpkg integrate install // vcpkg로 설치된 모든 라이브러리를 vs2022에 연동\n\n\nvcpkg integrate install은 한 번 해준 뒤에는 vcpkg install만 사용해 다운받으면 바로바로 사용할 수 있습니다.\n그런데 이렇게 command 창에서 직접 다운받는 경우는 Github에서 프로젝트를 새로 다운받으면 필요한 라이브러리를 매번 직접 설치해줘야 합니다.\n이걸 좀 더 쉽게 .json 파일을 통해 어떤 라이브러리들이 필요한지 설정해주면 Visual Studio에서 Build할때 필요한 라이브러리를 자동으로 설치할 수 있도록 해줄 수 있습니다.\n\n{\n  &quot;dependencies&quot;: [\n    &quot;assimp&quot;,\n    &quot;stb&quot;,\n    &quot;directxtk12&quot;,\n    &quot;directxmath&quot;,\n    &quot;directxmesh&quot;,\n    {\n      &quot;name&quot;: &quot;directxtex&quot;,\n      &quot;features&quot;: [\n        &quot;openexr&quot;\n      ]\n    },\n    {\n      &quot;name&quot;: &quot;imgui&quot;,\n      &quot;features&quot;: [\n        &quot;wchar32&quot;,\n        &quot;dx12-binding&quot;,\n        &quot;win32-binding&quot;\n      ]\n    }\n  ],\n  &quot;builtin-baseline&quot;: &quot;dd3097e305afa53f7b4312371f62058d2e665320&quot;\n}\n\n\n지금 프로젝트를 시작하면서 아마 필요할 것이라 생각되는 DirectX12, ImGui, Assimp 등의 라이브러리들을 설정해두었습니다.\n\n\n추가로 buildin-baseline이라는 설정이 있는데 이건 vcpkg 버전에 따라 다운받을 수 있는 라이브러리의 버전도 달라지기에 이걸 설정해서 항상 동일한 버전의 라이브러리들을 다운받을 수 있게 해주는 것입니다.\n\n\nvcpkg x-update-baseline --add-initial-baseline\n\n이걸 Command 창에서 실행해주면 baseline을 추가할 수 있습니다. 이건 맨 처음 실행하는 것으로 builtin-baseline이 json 파일에서 없어야 됩니다.\n이 파일이 있다고 바로 적용되는건 아니고 Visual Studio에서 추가로 사용할 것이라고 설정해줘야 합니다.\n\n\nvcpkg.json 사용 설정\n이렇게 Visual Studio의 project에서 Use Vcpkg Manifest를 true로 설정해줘야 json 파일을 사용해 build시 없는 라이브러리들을 다운받을 수 있게 됩니다.\n\n(참고로 이렇게 다운된 라이브러리들은 vcpkg_installed라는 폴더가 생기면서 저장되니 .gitignore 파일에서 이 폴더를 제외시켜주는게 좋습니다.)\n\n\n\n\n"},"content/Projects/JEngine---DX12/DirectX12/엔진-개발-02---Log-시스템":{"slug":"content/Projects/JEngine---DX12/DirectX12/엔진-개발-02---Log-시스템","filePath":"content/Projects/JEngine - DX12/DirectX12/엔진 개발 02 - Log 시스템.md","title":"엔진 개발 02 - Log 시스템","links":[],"tags":["CPP","Log"],"content":"\n이전에도 프로젝트를 진행하면서 규모가 작다면 그냥 코드를 한 줄씩 디버깅해도 문제가 없었는데 규모가 커지면서 기능별로 클래스를 분류하니 디버깅이 어려웠습니다. 디버깅의 편의성을 위해서 Logging을 위한 Class를 만들어주었습니다.\n강의 내용을 참고하고 AI를 활용해 주석을 추가해줬습니다.\n\nLogger Class\n전체적인 코드 변화는 아래 링크의 Github의 features branch에서 해당 Commit ID를 확인\n\ngithub.com/Jin-SukKim/JEngine/tree/features\n\nCommit ID : 49a2911f71c8c9ef74619c0d00bb9e4a2c89c862\n\n\n\npublic:\n...\n  static Logger&amp; getInstance() {\n      static Logger instance;\n      return instance;\n  }\n\n일단 Log 시스템은 프로그램 전체에서 1개만 있으면 된다고 생각하기에 Singleton Pattern을 사용했습니다.\n\nprivate:\n  std::ofstream logFile;\n  size_t messagesProcessed;\n\n2개의 멤버 변수를 가지고 있는데 logFile은 log를 파일로 출력하기 위한 변수이고 messageProcssed는 총 log가 몇 개 찍히는지 추적하기 위한 변수인데 logFile 변수만 가지고 있어도 됩니다.\n\nenum class LogLevel { INFO, WARNING, ERROR, DEBUG };\n\nLogLevel을 Logger Class 밖에 추가로 선언해줘서 각 Level 별로 Log를 분류해서 기록하도록 하려고 합니다.\n\n생성자와 소멸자\n  private:\n    Logger() : messagesProcessed(0) {\n        // Open log file (out: write mode, trunc: overwrite mode)\n        logFile.open(&quot;log.txt&quot;, std::ios::out | std::ios::trunc);\n \n        if (!logFile.is_open()) {\n            // cerr is the error output stream\n            std::cerr &lt;&lt; &quot;ERROR: Could not open log.txt for writing!&quot; &lt;&lt; std::endl;\n        }\n    }\n \n    // Delete Copy Constructor and Assignment Operator\n    Logger(const Logger&amp;) = delete;\n    Logger&amp; operator=(const Logger&amp;) = delete;\n\nSingleton Pattern을 사용하기 때문에 생성자를 private하게 만들었고 Logger가 처음 만들어질때 log 파일을 열도록 했습니다. std::ios::trunc로 인해 매번 프로그램이 실행될때마다 Log는 새로 작성됩니다.\n\npublic:\n  ~Logger() {\n      if (logFile.is_open()) {\n          // Write final statistics\n          logFile &lt;&lt; &quot;\\n=== Logging Session Ended ===&quot; &lt;&lt; std::endl;\n          logFile &lt;&lt; &quot;Total messages processed: &quot; &lt;&lt; messagesProcessed &lt;&lt; std::endl;\n          logFile.flush();\n          logFile.close();\n      }\n  }\n\nSingleton Pattern을 사용했으므로 아마 프로그램이 종료될때까지 이 클래스 객체는 유지될텐데 클래스가 없어질때, 즉 프로그램이 종료될때 더 이상 기록할 Log가 없으니 log 파일을 닫아 정리해줍니다.\n\nLogging\n// Using Fold Expressiong (C++ 17 and later)\ntemplate &lt;typename T, typename... Args&gt;\nvoid formatToStream(std::ostringstream&amp; oss, T&amp;&amp; firstArg, Args&amp;&amp;... args) {\n    oss &lt;&lt; std::forward&lt;T&gt;(firstArg);\n    if constexpr (sizeof...(args) &gt; 0) {\n        ((oss &lt;&lt; &quot; &quot; &lt;&lt; std::forward&lt;Args&gt;(args)), ...);\n    }\n}\n \nstd::string getLogLevelString(LogLevel level) {\n    switch (level) {\n    case LogLevel::INFO:\n        return &quot;[INFO]&quot;;\n    case LogLevel::WARNING:\n        return &quot;[WARNING]&quot;;\n    case LogLevel::ERROR:\n        return &quot;[ERROR]&quot;;\n    case LogLevel::DEBUG:\n        return &quot;[DEBUG]&quot;;\n    default:\n        return &quot;[UNKNOWN]&quot;;\n    }\n}\n\n{C++}getLogLevelString() 함수로 어떤 LogLevel의 Log가 기록될지 string을 반환해줍니다. 이 LogLevel을 Log Message 앞에 출력해서 어떤 Level인지 추가로 알 수 있게 해줍니다. 이러면 나중에 Log 파일이나 Command 창에서 집중적으로 봐야할 Log가 뭔지 알 수 있어 디버깅에 도웁이 될 수 있습니다.\n{C++}formatToStream()은 입력받은 인자들을 Log 파일에 출력하는데 여기서는 가변 길이 템플릿을 사용해줬습니다. 추가로 C++ 17부터 사용할 수 있는 Fold Expression을 활용해서 함수를 최적화할 수 있습니다.\n\npublic:\n  ...\n  // Writes a log message to console and file.\n  static void PrintLog(const std::string&amp; message, LogLevel level = LogLevel::INFO) {\n      auto&amp; logger = getInstance();\n \n      std::string levelStr = logger.getLogLevelString(level);\n      std::string fullMessage = std::format(&quot;{} {}&quot;, levelStr, message);\n \n      std::cout &lt;&lt; fullMessage &lt;&lt; std::endl;\n \n      if (logger.logFile.is_open()) {\n          logger.logFile &lt;&lt; fullMessage &lt;&lt; std::endl;\n          logger.logFile.flush();\n          logger.messagesProcessed++;\n      } else {\n          std::cerr &lt;&lt; &quot;ERROR: Log file is not open! Current Message lost: &quot; &lt;&lt; message\n                    &lt;&lt; std::endl;\n      }\n  }\n \n  // Logs variadic arguments using formatToStream.\n  template &lt;typename... Args&gt;\n  static void Log(LogLevel level, Args&amp;&amp;... args) { \n      auto&amp; logger = getInstance();\n \n      // Concatenate multiple arguments into a single string\n      std::ostringstream oss;\n      logger.formatToStream(oss, std::forward&lt;Args&gt;(args)...);\n      std::string message = oss.str();\n \n      std::string levelStr = logger.getLogLevelString(level);\n      std::string fullMessage = std::format(&quot;{} {}&quot;, levelStr, message);\n \n      std::cout &lt;&lt; fullMessage &lt;&lt; std::endl;\n \n      if (logger.logFile.is_open()) {\n          logger.logFile &lt;&lt; fullMessage &lt;&lt; std::endl;\n          logger.messagesProcessed++;\n      } else {\n          std::cerr &lt;&lt; &quot;ERROR: Log file is not open! Current Message lost: &quot; &lt;&lt; message\n                    &lt;&lt; std::endl;\n      }\n  }\n\n이 두 함수는 결국 Message를 입력받아서 Console과 Log 파일에 Write를 해주는 동일한 기능을 하는 함수인데 기본적으로 std::string만 받는 함수와 string 말고도 int, bool 등 다양한 Type의 변수를 받아서 출력할 수 있는 함수 2개를 만들었습니다.\n\n굳이 이렇게 2개로 나눌 필요없이 2번째 함수만 남겨둬도 된다고 생각은 하고 있고 추후 코드를 정리할 수 있을 것 같습니다.\n\n\n\nLogging Helper 함수들\n// Logs an INFO-level message using std::format.\n// Example: LogInfo(&quot;Player spawned at ({}, {})&quot;, x, y);\ntemplate &lt;typename... Args&gt;\nvoid LogInfo(std::format_string&lt;Args...&gt; fmt, Args&amp;&amp;... args) {\n    std::string message = std::format(fmt, std::forward&lt;Args&gt;(args)...);\n    Logger::PrintLog(message, LogLevel::Info);\n}\n \n// Logs a WARNING-level message using std::format.\n// Example: LogWarning(&quot;Low memory: {} MB&quot;, availableMemory);\ntemplate &lt;typename... Args&gt;\nvoid LogWarning(std::format_string&lt;Args...&gt; fmt, Args&amp;&amp;... args) {\n    std::string message = std::format(fmt, std::forward&lt;Args&gt;(args)...);\n    Logger::PrintLog(message, LogLevel::Warning);\n}\n \n// Logs an ERROR-level message using std::format.\n// Example: LogError(&quot;Failed to load asset: {}&quot;, filename);\ntemplate &lt;typename... Args&gt;\nvoid LogError(std::format_string&lt;Args...&gt; fmt, Args&amp;&amp;... args) {\n    std::string message = std::format(fmt, std::forward&lt;Args&gt;(args)...);\n    Logger::PrintLog(message, LogLevel::Error);\n}\n \n// Logs a DEBUG-level message using std::format.\n// Example: LogDebug(&quot;FPS: {}, Frame time: {} ms&quot;, fps, frameTime);\ntemplate &lt;typename... Args&gt;\nvoid LogDebug(std::format_string&lt;Args...&gt; fmt, Args&amp;&amp;... args) {\n    std::string message = std::format(fmt, std::forward&lt;Args&gt;(args)...);\n    Logger::PrintLog(message, LogLevel::Debug);\n}\n \n// Logs multiple arguments separated by spaces using formatToStream.\n// More flexible than std::format for mixing different types.\n// Example: LogMultiple(LogLevel::INFO, &quot;Entity&quot;, entityId, &quot;HP&quot;, hp, &quot;Mana&quot;, mana);\ntemplate &lt;typename... Args&gt;\nvoid LogMultiple(LogLevel level, Args&amp;&amp;... args) {\n    Logger::Log(level, std::forward&lt;Args&gt;(args)...);\n}\n \n// Logs an error message and terminates the program.\n// Calls assert(false) and std::exit(EXIT_FAILURE).\n// Example: ExitWithMessage(&quot;Fatal error: {}&quot;, errorMessage);\ntemplate &lt;typename... Args&gt;\nvoid ExitWithMessage(std::format_string&lt;Args...&gt; fmt, Args&amp;&amp;... args) {\n    std::string message = std::format(fmt, std::forward&lt;Args&gt;(args)...);\n    Logger::PrintLog(message, LogLevel::Error);\n    assert(false);\n    std::exit(EXIT_FAILURE);\n}\n \n// DirectX HRESULT error handling with C++20 std::source_location\n// Automatically captures file, line, and function information\n// Example: ThrowIfFailed(D3D12CreateDevice(...));\ninline void ThrowIfFailed(\n    HRESULT hr, \n    const std::source_location&amp; location = std::source_location::current()\n) {\n    if (FAILED(hr)) {\n        std::string errorMsg = std::format(\n            &quot;DirectX Error\\n&quot;\n            &quot;  File: {}\\n&quot;\n            &quot;  Line: {}\\n&quot;\n            &quot;  Function: {}\\n&quot;\n            &quot;  HRESULT: 0x{:08X}&quot;,\n            location.file_name(), \n            location.line(),\n            location.function_name(),\n            static_cast&lt;unsigned&gt;(hr)\n        );\n        LogError(&quot;{}&quot;, errorMsg);\n        throw std::runtime_error(errorMsg);\n    }\n}\n\nLogger 클래스에서 만든 printLog()나 log() 함수를 더 편리하게 사용할 수 있도록 도와주는 함수들을 만들어줬습니다. 이 함수들을 통해서 간단하게 각 LogLevel 별로 Log를 출력할 수 있습니다.\n\n간단한 사용 예시\n// Example usage:\n  using namespace JEngine;\n \n  // 1. std::format-based logging (recommended)\n  LogInfo(&quot;Application started&quot;);\n  LogInfo(&quot;Player ID: {}, Name: {}&quot;, 123, &quot;Player1&quot;);\n  LogWarning(&quot;Memory usage: {}%&quot;, 85);\n  LogError(&quot;Failed to load file: {}&quot;, &quot;texture.png&quot;);\n  LogDebug(&quot;Frame time: {} ms&quot;, 16.67f);\n \n  // 2. formatToStream-based logging (flexible type mixing)\n  LogMultiple(LogLevel::INFO, &quot;Entity&quot;, 42, &quot;HP&quot;, 100, &quot;Position&quot;, 10.5f, 20.3f);\n  // Output: [INFO] Entity 42 HP 100 Position 10.5 20.3\n \n  // 3. Exit on critical error\n  ExitWithMessage(&quot;Critical error: {}&quot;, errorCode);\n \n/*\nOutput example:\n  [INFO] Application started\n  [INFO] Player ID: 123, Name: Player1\n  [WARNING] Memory usage: 85%\n  [ERROR] Failed to load file: texture.png\n  [DEBUG] Frame time: 16.67 ms\n  [INFO] Entity 42 HP 100 Position 10.5 20.3\n*/"},"content/Projects/JEngine---DX12/DirectX12/엔진-개발-03---Direct3D":{"slug":"content/Projects/JEngine---DX12/DirectX12/엔진-개발-03---Direct3D","filePath":"content/Projects/JEngine - DX12/DirectX12/엔진 개발 03 - Direct3D.md","title":"엔진 개발 03 - Direct3D","links":[],"tags":["Graphics","DirectX12"],"content":"목표\n\nDirect3D의 역할 이해\nDirect3D에서 COM의 역할 이해\n2차원 이미지의 저장방식, 페이지 전환, 깊이 버퍼링 Multi-Sampling 같은 그래픽 개념\n성능 카운터 함수들을 이요해 고해상도 타이머 값을 얻기\nDirect3D 초기화\n\nDirect3D 12 개요\n\nDirect3D는 GPU를 제어하는 저수준 Graphics API\n\n3차원 그래픽 가속 기능을 이용해 3D World를 렌더링 가능\n\n\n응용 프로그램과 그래픽 하드웨어 사이에 Direct3D라는 Interface를 통해 GPU에 명령을 주는데 Driver가 내부적으로 해당 명령을 받아서 일하므로 세부사항은 걱정할 필요가 없음\n\n단 NVIDIA, AMD, Intel 등 GPU 제조사의 Driver에서 DX12를 지원해야함\n\n\nDX12에 몇 가지 새로운 렌더링 기능이 추가되었지만 이전 버전들고 비교하면 GPU의 부담을 줄이고 Multi-Thread 지원을 개선하기 위해 설계를 다시 했다는 점\n\n이런 성능상의 목표를 달성하기 위해 DX12는 DX11보다 훨씬 낮은 수준의 API가 되었음\n즉, 사용하기 더 어려워졌다는 의미\n\n\nDX12는 이저보다 추상화가 줄었고 개발자가 직접 관리해야 할 사항들이 늘어나 어려워졌지만 성능이 개선됨\n\nCOM (Component Object Model)\n\nCOM은 DX의 프로그래밍 언어 독립성과 하위 호환성을 가능하게 해줌\n\n즉, 굳이 C++가 아니라 다른 언어로도 프로그램을 만들면 Window(COM)이 알아서 DirectX에 연결해줌\nDirectX의 버전이 바뀌어도 호환됨\n\n\nCOM 객체를 흔히 COM Interface라고 부르지만 여기선 COM 객체를 C++ 클래스로 간주하고 사용해도 무방함\n\nC++로 DX 응요 프로그램을 프로그래밍할 때 COM의 세부사항은 들어나지 않기 때문\n\n\n알아야 할 것은 필요한 COM Interface를 갈리키는 포인터를 특별한 함수들을 이용하거나 다른 COM Interface의 Method를 이용해 얻는 방법 뿐임\n\nnew로 직접 생성할 일은 없음\n\n\n그리고 사용이 끝나면 delete으로 삭제하는게 아니라 Releate Method를 호출해줘야 함\n\n참고로 COM 객체는 참조 횟수가 0이 되면 메모리에서 해제됨\n\n\nCOM 객체의 수명 관리를 돕기 위해, Windows Runtime Library (WRL)은 Microsoft::WRL::ComPtr 이라는 클래스를 제공함\n\n사용하려면 #include &lt;wrl.h&gt;를 사용\n이 클래스는 COM 객체를 위한 smart pointer\n\n\n범위를 벗어난 ComPtr Instance는 COM 객체에 대해 자동으로 Release를 호출해 직접 호출할 필요가 없어짐\nDX12에서 사용하는 중요한 3가지 Method\n\nGet : COM Interface를 가리키는 포인터를 Return\n\n해당 COM Interface Pointer 형식의 Paramter를 받는 함수를 호출할 때 흔히 사용됨\n\n\nGetAddressOf : COM Interface를 가리키는 포인터의 Address를 Return\n\n함수 매개변수를 통해 COM Interface Pointer를 돌려받을 때 흔히 사용됨\n\n\nReset : ComPtr Instance를 nullptr로 설정하고 COM Interface의 참조 횟수를 1 감소\n\n이 함수를 사용하는 대신 직접 nullptr로 지정해도 됨\n\n\n\n\n참고로 COM Interface들은 이름이 대문자 I로 시작함\n\nex) command list를 나타내는 COM Interface의 이름은 ID3D12GraphicsCommandList\n\n\n\nTexture 형식\n\n2차원 Texture는 보통 이미지를 저장하지만 Normal, Depth 등 다른 필요한 값들도 저장할 수 있음\n\n범용적으로 사용 가능\n\n\n1차원 Texture나 3차원 Texture도 존재하는데 이 Texture는 단순히 Value Array인 것만은 아니고 Texture에 MipMap이 존재할 수 있고 GPU는 Filtering, Multi-Sampling 등의 특별한 연산을 Texture에 적용할 수 있음\n하지만  Texture에 아무 자료나 담을 수 있는 것은 아님\n\n특정 Format의 자료 원소들만 담을 수 있는데 구체적인 형식은 DXGI_FORMAT이라는 Enum으로 지정\n\n\nDXGI_FORMAT의 몇 가지 Format\n\nDXGI_FORMAT_R32G32B32_FLOAT : 각 원소는 32bit 부동소수점 성분 3개\nDXGI_FORMAT_R16G16B16A16_UNROM : 각 원소는 [0, 1] 범위의 16bit 성분 4개\nDXGI_FORMAT_R32G32_UINT : 각 원소는 부호없은 32bit 정수 성분 2개\nDXGI_FORMAT_R8G8B8A_UNORM : 각 원소는 [0, 1] 범위의 부호 있는 8bit 성분 4개\nDXGI_FORMAT_R8G8B8A8_SNORM : 각 원소는 [-1, 1] 범위로 부호있는 8bit 정수 4개\nDXGI_FORMAT_R8G8B8A8_SINT : 각 원소는 [-128, 128] 범위의 부호있는 8bit 정수 4개\nDXGI_FORMAT_R8G8B8A8_UINT : 각 원소는 [0, 255] 범위의 부호없는 8bit 정수 4개\n\n\nR = Red, G = Green, B = Blue, A = Alpha 성분을 의미\n그래픽에서 하나의 색상은 3원색인 적, 녹, 청 조합으로 만들어짐\n\nex) 노란색 = 빨간색 + 노란색\n\n\nAlpha는 일반적으로 투명도를 제어하는데 사용되는데 Texture에 반드시 색상을 담아야 하는건 아님\n\n그래서 DXGI_FORMAT_R32G32B32_FLOAT에 색상값이 아니라 3차원 벡터를 담을 수 있음\n\n\ntypeless Texture들도 있는데 이런 Texture는 일단 메모리만 확보해두고 자료의 구체적인 해석 방식은 나중에 Texture를 Pipeline에 묶을 때 지정하는(C++의 reinterpret_cast와 비슷하게) 용도로 사용됨\n\nex) DXGI_FORMAT_R16G16B16A16_TYPELESS : 16bit 성분 4개를 할당하되 각 16bit의 구체적인 자료 형식 (int, float, uint 등)은 지정하지 않음\n\n\n나중에 사용되는데 DXGI_FORMAT Enum은 Vertex 자료 형식과 Index 자료 형식을 서술할 때도 사용됨\n\nSwap-Chain과 Page 전환\n\nAnimation의 한 Frame 전체를 화면 바깥의(off-screen) Texture에 그려줌\n\n이 Texture를 Back Buffer라고 부름\n\n\n주어진 한 Frame을 위해 장면 전체를 Back Buffer에 그린 다음에는, 그 Back Buffer를 하나의 완전한 Frame으로서 화면에 표시함\n\n이러면 화면을 보는 사용자에게는 Frame이 그려지는 과정이 나타나지 않음\n이걸 Double Buffering이라 부름\n\n\n이중 버퍼링을 효율적으로 구현하려면 하드웨어로 관리되는 2개의 Texture buffer가 필요한데, 하나응 Front Bufefr이고 다른 하나는 Back Buffer\n화면에는 Front Buffer에 담긴 이미지 자료가 표시되는데 이 시간 동안 다음 Frame을 Back Buffer에 그리고 다 그려지면 Front Buffer와 Back Buffer의 역할을 맞바꿈\n\n\n이렇게 Back Buffer와 Front Buffer의 역할을 교환해서 Page가 전환되게 하는 것을 Direct3D에서는 Presenting이라고 부름\n효율적인 방식인데 Buffer의 내용을 바꾸는게 아니라 포인터만 서로 바꿔주면 되기 때문\n\n\nFront Buffer와 Back Buffer는 하나의 Swap Chain을 형성하는데 Direct3D에서 이걸 IDXGISwapChain이란 Interface가 담당함\n이 Interface는 Front Buffer Texture와 Back Buffer Texture를 담으며, Buffer 크기 변경을 위한 Method(IDXGISwapChain::ResizeBuffers)와 Buffer의 화면에 그리기 위한 Method(IDXGISwapChain:Present)도 제공\nBuffer를 3개 사용하면 Triple Buffering이라고 부름\n참고로 Back Buffer는 Texture이므로 원소를 Texel이라고 불러야 하지만, 그냥 pixel이라고 부르는 경우도 많음\n\n이는 색상 정보를 담기 때문으로 색상이 아닌 정보를 담은 Texture의 원소를 Pixel이라고 부르기도 하긴 함\n\n\n\nDepth Buffering\n\n각 픽셀에 Depth 정보를 저장\n픽셀의 깊이는 [0.0, 1.0] 범위로 0.0은 view frustum 안에서 가장 가까운 Near Plane 위의 물체에 해당, 1.0은 가장 먼, Far Plane에 해당함\nDepth Buffer의 원소들과 Back Buffer의 pixel들은 1대 1로 대응됨\n여러 물체들을 렌더링할때 한 물체의 픽셀들이 다른 물체보다 앞에 있는지 판정하기 위해 Depth Buffer 또는 Z-Buffering이라는 기법을 사용\n\n중요한 점은, Depth Buffering을 이요하면 물체들을 그리는 순서와 무관하게 물체들이 제대로 가려진다는 점\n\n\n응용 프로그램은 렌더링을 수행하기 전에 먼저 Back Buffer를 기본 색상(검은색이나 흰색 등 지정 가능)으로 지워줌\n\n이때 Depth Buffer도 기본값으로 지워지는데 일반적으로 한 픽셀이 가질 수 있는 최대 깊이인 1.0을 기본값으로 사용\n\n\n물체를 렌더링할때 해당 물체의 픽셀의 깊이 값을 알 수 있는데 이때 Depth Buffer에 저장된 깊이값도가 작은 경우에만 Back Buffer와 Depth Buffer에 저장됨\n\n이런 방식으로 인해 가장 가까운 물체의 픽셀이 렌더링됨\n\n\n즉, Depth Buffering Algorithm은 렌더링되는 각 픽셀의 깊이 값을 계산해서 Depth Testing을 수행해 가까운걸 렌더링하는 방식\n\nDepth Testing은 Back Buffer의 특정 픽셀 위치에 기록될 픽셀들의 Depth들을 비교\n깊이 값을 비교했을때 더 가까운 픽셀의 색을 저장\n\n\nDepth Buffer는 하나의 Texture이므로 생성 시 특정한 Format을 지정해줘야 함\n\nDXGI_FORMAT_D32_FLOAT_S8X25_UINT : 각 Texel은 32bit 부동소수점 Depth 값과 [0, 255] 범위의 부호없는 8bit 정수 Stencil 값, 그리고 다른 용도 없이 padding 용으로만 쓰이는 24bit로 구성\nDXGI_FORMAT_D32_FLOAT : 각 Texel은 하나의 32bit 부동소수점 깊이값\nDXGI_FORMAT_D24_UNORM_S8_UINT : 각 Texel은 [0, 1] 구간으로 부호없는 24bit 깊이값 하나의 [0, 255] 범위의 부호없는 8bit 정수 Stencil 값으로 구성\nDXGI_FORMAT_D16_UNORM : 각 Texel은 [0, 1] 범위로 부호없는 16bit Depth값\n\n\n참고로 Stecil Buffer는 반드시 사용해야 하는 것은 아니나, 만일 사용한다면 Stencil Buffer는 항상 Depth Buffer와 같은 Texture에 포함됨\n\n그래서 보통 Depth-Stencil Buffer라고 불림\n\n\n\nResource와 Descriptor\n\n렌더링 과정에서 CPU는 Resource들에 Write하거나 Read함\nRendering 명령을 제출하기 전에, 먼저 해당 Renering 호출이 참조할 자원들을 렌더링 파이프라인에 묶어야(bind)함\n\n이걸 자원을 파이프라인에 연결(Link) 또는 Binding한다고 함\n\n\nRendering 호출마다 달라지는 자원들도 있으며, 따라서 필요하다면 Rendering 호출마다 자원들의 Binding을 갱심해야 함\n그런데 GPU 자원들이 파이프라인에 직접 Binding되는게 아니라 이 자원을 참조하는 Descriptor 객체를 Binding해줌\nDescriptor는 Resource를 GPU에 간접적으로 Binding할 수 있게 해줌\n\nVulkan에서도 Descriptor, Desciptor Set등을 사용했음\n\n\n이렇게 간접층을 두는 이뉴는 GPU 자원이라는 것이 사실상 범용적인 메모리 조각이기 때문\n\n자원은 범용적이므로, 같은 자원을 렌더링 파이프라인의 서로 다른 단계(Stage)들에서 사용할 수 있음\nex) Write하는 Render Target으로 사용하는데 다른곳에서 Read하는 Texture로 사용할 수 있음\n자원 자체는 Write/Read에 대해서 구분하지 않음\n\n\n또한, 자원의 일부 영역만 렌더링 파이프라인에묶오 싶은 때가 있는데, 자우너 자체에는 이런 정보가 없고 애초에 자원을 형식없이 생성할 수 있음\n\n무형식으로 만들면 GPU는 자원의 형식을 알 수 없음\n\n\nDescriptor는 Resource를 지정하는 수단일 뿐만 아니라, Resource를 GPU에 어떻게 사용할지 알려주는 것이기도 함\n\nDirect3D에게 자원의 사용법(Resource를 Pipeline의 어떤 Stage에 묶어야할지 등)을 알려줌\n가능한 경우 Pipeline에 묶을 자원의 부분 영역을 Descriptor로 지정할 수 있음\n무형식으로 생성된 자원의 경우, 그 자원을 참조하는 Descriptor를 생성할 때 그 자원의 구체적인 형식을 명시할 수 있음\n\n이것도 엔진 만들때 좋을 듯\n\n\n\n\n참고로 Veiw는 Descriptor와 동의어\n\nView라는 용어는 DX12 이전 버전들에서 사영되었고 DX12에서도 일부 사용되고 있음\n\n\nDescriptor는 Resource의 사용버에 따라 여러 종류(형식)이 존재\n\nConstant Buffer = CBV\nShader Resource = SRV\nUnordered Access View = UAV\nSampler Descriptor는 Texture를 적용할때 쓰이는 Sampler를 설명\nDepth Stencil Buffer = DSV\n\n\nDescriptor Heap은 Descriptor들의 배열\n\n프로그램이 사용하는 Descriptor들이 저장되는 곳이 Descriptor Heap\nDescriptor 종류마다 개별적인 Descriptor Heap이 필요하고 같은 종류는 같은 Descriptor Heap에 저장됨\n또한, 한 종류의 Descriptor에 대해 여러 개의 Heap을 사용할 수 있음\n\n\n하나의 Resource를 참조하는 Descriptor가 1개뿐이어야 하는 것은 아님\n\n한 Resource의 여러 부분 영역을 여러 Descriptor가 참조할 수 있음\n또한, 하나의 자원을 렌더링 파이프라인의 여러 단계에서 Binding할 수 있는데, 단계마다 개별적인 Descriptor가 필요함\n\nex) 하나의 Texture를 Render Target이나 Shader Resource로 사용하는 경우, RTV 형식의 Descriptor와 SRV 형식의 Descriptor를 만들어 둘 다 사용\n\n\n무형식 Resource를 만든 경우 Texture의 원소를 이를테면 부동소수점 값으로 사용할 수도 있고 정수로 사용할 수도 있는데, 이렇게 하려면 2개의 Descriptor, 즉 부동소수점 형식을 지정하는 Descriptor와 정수 형식을 지정하는 Descriptor 2개가 필요함\n\n\nDescriptor들은 프로그램 초기화 시점에서 생성해야 됨\n\n이는 이때 일정 정도의 형식 점검과 유효성 검증이 일어나기 때문이고 초기화 시점에 생성하는 것이 실제 실행 시점에서 생성하는 것보다 좋음\n참고로 무형식 자원은 다양한 방식으로 해석할 필요가 있는 경우만 사용하고 아니면 형식을 꼭 지정해서 자원을 만들어야 Driver에서 최적화를 수행해줌\n\n\n\nMulti-Sampling 이론\n\n계단 현상을 없애기 위한 Anti-Aliasing\n\nDirect3D에서 지원하는 기법\n\n\n일부 계산 결과를 subpixel들 사이에서 공유하기 때문에 Super Sampling 기법보다 비용이 적음\n\n이미지 색상을 각 부분픽셀마다 계산하는 것이 아니라 픽셀당 한 번만 계산하고(픽셀의 중심에서), 그 색상과 부분픽셀들의 가시성(이를 위해 부분픽셀당 Depth-Stencil Testing을 함)과 포괄도(부분픽셀을 다각형이 어느 정도나 덮고 있는지를 뜻하는 값)을 이용해 최종 색살을 결정\n\n\n하지만 결국 추가 계산이 필요하기에 실시간 렌더링에서는 사용하지 않거나 다른 방식을 주로 사용하는 경우가 많음\n\nDirect3D의 Multi-Sampling\n\nDXGI_SAMPLE_DESC라는 구조체를 채워줘야 함\n이 구조체는 2개의 멤버 변수로 이루어져 있음\n\ntypedef struct DXGI_SAMPLE_DESC {\n\tUINT Count;\n\tUINT Quality;\n} DXGI_SAMPLE_DESC;\n\nCount는 픽셀당 추출할 표번의 개수를 지정\nQuality는 원하는 Quality Level을 지정\n표본의 개수가 많을수록, 품질 수준이 높을수록 비용이 증가하므로, 비용과 속도 사이의 절충선을 잘 잡아야 함\n\nQuality Level들의 범위는 Texture 형식과 픽셀당 표본 개수에 의존함\n\n\n주어진 Texture 형식과 표본 개수의 조합에 대한 Quality Level들의 개수는 ID3D12Device::CheckFeatureSupport라는 method로 알아낼 수 있음\n\n아래 코드는 사용 예시\n\n\n\ntypedef struct D3D12_FEATURE_DATA_MULTISAMPLE_QUALITY_LEVELS {\n\tDXGI_FORMAT Format;\n\tUINT SampleCount;\n\tD3D12_MULTISAMPLE_QUALITY_LEVELS_FLAG Flags;\n\tUINT NumQualityLevels;\n} D3D12_FEATURE_DATA_MULTISAMPLE_QUALITY_LEVELS;\n \nD3D12_FEATURE_DATA_MULTISAMPLE_QUALITY_LEVELS msQualityLevels;\nmsQualityLevel.Format = mBackBufferFormat;\nmsQualityLevel.SampleCount = 4;\nmsQualityLevel.Flags = D3D12_MULTISAMPLE_QUALITY_LEVELS_FLAG_NONE;\nmsQualityLevel.NumQualityLevels = 0;\nThrowIfFailed(md3dDevice-&gt;CheckFeatureSupport(\n\tD3D12_FEATURE_MULTISAMPLE_QUALITY_LEVELS,\n\t&amp;msQualityLevel,\n\tsizeof(msQualityLevel)\n));\n\n이 Method의 둘째 매개변수가 입력과 출력 모두에 쓰인다는 점으로 둘째 매개변수로 지정된 구조체에서 Texture 형식과 표본 개수를 읽고, 그에 해당하는 품질 수준 개수를 그 구조체의 NumQualityLevels 멤버에 설정함\n주어진 Texture 형식과 표본 개수의 조합에 대해 유효한 품질 수준들은 0에서 NumQualityLevels - 1까지임\n\n한 픽셀에서 추출할 수 있는 최대 표본 개수는 다음과 같이 정의\n#define D3D12_MAX_MULTISAMPLE_SAMPLE_COUNT (32)\n\n\n그러나 실제로는 성능 및 메모리 비용의 절충선으로 표본을 4개나 8개만 추출하는 경우가 많음\n\nMulti-Sampling을 사용하고 싶지 않으면 SampleCount를 1로, QualityLevel을 0으로 설정하면 됨\n\n\n참고로 DXGI_SAMPLE_DESC 구조체는 Swap-Chain Buffer들과 Depth Buffer 모두에 필요함\n\n또한 Back Buffer와 Depth Buffer를 생성할 때 동일한 Multi-Sample 설정을 적용해야 함\n\n\n\nFeature Level\n\nD3D_FEATURE_LEVEL이라는 Enum으로 사용하는데 대략 DirectX의 버전 9부터 12까지의 버전들에 대응됨\nGPU가 지원하는 기능들의 집합을 정의\n\nGPU에서 이 버전을 지원하는지 확인하는 과정이 필요하고 어떤 버전을 사용할지 지정해주면 됨\n\n\n\nDXGI (DirectX Graphics Infrastructure)\n\nDXGI는 Direct3D와 함께 쓰이는 API\n\nDXGI의 기본 개념은 여러 그래픽 APi들에 공통인 그래픽 관련 작업들이 존재한다는 것\nex) 2차원 애니메이션을 위해선 2차원 렌더링 API에도 3차원 렌더링 API처럼 swap-chain이 필요함\n\n그래서 swap-chain을 대표하는 interface인 IDXGISwapChain은 실제로 DXGI API의 일부 (Direct3D API가 아님)\n\n\n\n\n즉, DXGI는 공통적인 그래픽 기능을 처리함\n\n전체 화면 모드 전환, 디스플레이 어댑터, 모니터, 지원되는 디스플레이 모드(해상도, Frame 등) 같은 그래픽 시스템 정보를 확인 등의 기능을 제공\n지원되는 표현 형식들도 DXGI에 정의되어 있음\n\nDXGI_FORMAT\n\n\n\n\n\nDirect3D 초기화 과정에 사용되는 DXGI 개념들과 Interface들\n\nIDXGIFactory : IDXGISwapChain Interface 생성과 디스플레이 어댑터 관련해서 사용됨\n\nDisplay adapter는 그래픽 기능성을 구현\n\nDisplay Adapter는 물리적인 하드웨어 장치 (GPU)\n하드웨어 그래픽 기능을 휴앤내는 소프트웨어 디스플레이 어댑터도 존재함\n\n\n하나의 시스템에 여러 개의 어댑터가 있을 수 있음 (여러 GPU를 사용하는 경우)\n\n\nIDXGIAdapter : Display Adapter를 대표하는 Interface\n\n아래의 함수는 시스템에 있는 모든 Adapter를 출력하는 방법\n\n\n\nvoid D3DApp::LogAdapters()\n{\n    UINT i = 0;\n    IDXGIAdapter* adapter = nullptr;\n    std::vector&lt;IDXGIAdapter*&gt; adapterList;\n    while(mdxgiFactory-&gt;EnumAdapters(i, &amp;adapter) != DXGI_ERROR_NOT_FOUND)\n    {\n        DXGI_ADAPTER_DESC desc;\n        adapter-&gt;GetDesc(&amp;desc);\n \n        std::wstring text = L&quot;***Adapter: &quot;;\n        text += desc.Description;\n        text += L&quot;\\n&quot;;\n \n        OutputDebugString(text.c_str());\n \n        adapterList.push_back(adapter);\n        \n        ++i;\n    }\n \n    for(size_t i = 0; i &lt; adapterList.size(); ++i)\n    {\n        LogAdapterOutputs(adapterList[i]);\n        ReleaseCom(adapterList[i]);\n    }\n}\n\nIDXGIOutput : 디스플레이 출력을 대표하는 Interface로 모니터가 대표적인 디스플레이 출력의 한 예시\n\n각 어댑터에는 출력들의 목록이 연관되어 있음\nex) 그래픽 카드가 2개, 모니터가 3개 연결되어 있으며 세 모니터 중 둘은 한 GPU에, 나머지 하나는 다른 한 GPU에 물려있다면 각각 GPU에 연결된 출력 목록을 확인할 수 있음\n아래는 한 어댑터에 연관된 모든 출력을 확인하는 코드로 위의 어댑터를 확인하며 동시에 확인해줌\n\n\n\nvoid D3DApp::LogAdapterOutputs(IDXGIAdapter* adapter)\n{\n    UINT i = 0;\n    IDXGIOutput* output = nullptr;\n    while(adapter-&gt;EnumOutputs(i, &amp;output) != DXGI_ERROR_NOT_FOUND)\n    {\n        DXGI_OUTPUT_DESC desc;\n        output-&gt;GetDesc(&amp;desc);\n        \n        std::wstring text = L&quot;***Output: &quot;;\n        text += desc.DeviceName;\n        text += L&quot;\\n&quot;;\n        OutputDebugString(text.c_str());\n \n        LogOutputDisplayModes(output, mBackBufferFormat);\n \n        ReleaseCom(output);\n \n        ++i;\n    }\n}\n\nDXGI_MODE_DESC : 하나의 모니터는 여러 Display Mode를 지원하는데 이 구조체는 하나의 Display Mode를 설명하는 멤버들이 저장됨\n\ntypedef struct DXGI_MODE_DESC\n{\n    UINT Width; // 가로 해상도\n    UINT Height; // 세로 해상도\n    DXGI_RATIONAL RefreshRate;\n    DXGI_FORMAT Format; // 디스플레이 형식\n    DXGI_MODE_SCANLINE_ORDER ScanlineOrdering; // 스캔 방식 : Progressive or interlaced\n    DXGI_MODE_SCALING Scaling; // 영상을 모니터 크기에 맞게 늘리거나 줄이는 방식\n} DXGI_MODE_DESC;\n \ntypedef struct DXGI_RATIONAL\n{\n    UINT Numerator;\n    UINT Denominator;\n} DXGI_RATIONAL;\n \ntypedef enum DXGI_MODE_SCANLINE_ORDER\n{\n    DXGI_MODE_SCANLINE_ORDER_UNSPECIFIED        = 0,\n    DXGI_MODE_SCANLINE_ORDER_PROGRESSIVE        = 1,\n    DXGI_MODE_SCANLINE_ORDER_UPPER_FIELD_FIRST  = 2,\n    DXGI_MODE_SCANLINE_ORDER_LOWER_FIELD_FIRST  = 3\n} DXGI_MODE_SCANLINE_ORDER;\n \ntypedef enum DXGI_MODE_SCALING\n{\n    DXGI_MODE_SCALING_UNSPECIFIED   = 0,\n    DXGI_MODE_SCALING_CENTERED      = 1,\n    DXGI_MODE_SCALING_STRETCHED     = 2\n} DXGI_MODE_SCALING;\n\n아래의 코드는 주어진 출력과 디스플레이 형식을 지원하는 모든 디스플레이 모드를 담은 목록을 얻는 방법\n\nvoid D3DApp::LogOutputDisplayModes(IDXGIOutput* output, DXGI_FORMAT format)\n{\n    UINT count = 0;\n    UINT flags = 0;\n \n    // Call with nullptr to get list count.\n    output-&gt;GetDisplayModeList(format, flags, &amp;count, nullptr);\n \n    std::vector&lt;DXGI_MODE_DESC&gt; modeList(count);\n    output-&gt;GetDisplayModeList(format, flags, &amp;count, &amp;modeList[0]);\n \n    for(auto&amp; x : modeList)\n    {\n        UINT n = x.RefreshRate.Numerator;\n        UINT d = x.RefreshRate.Denominator;\n        std::wstring text =\n            L&quot;Width = &quot; + std::to_wstring(x.Width) + L&quot; &quot; +\n            L&quot;Height = &quot; + std::to_wstring(x.Height) + L&quot; &quot; +\n            L&quot;Refresh = &quot; + std::to_wstring(n) + L&quot;/&quot; + std::to_wstring(d) +\n            L&quot;\\n&quot;;\n \n        ::OutputDebugString(text.c_str());\n    }\n}\n\n이런 디스플레이 모드 확인은 전체 화면 모드로 갈 떄 특히나 중요함\n\n전체 화면 성능을 극대화하려면, 지정된 모드가 모니터가 지원하는 한 디스플레이 모드와 일치해야 됨\n\n\n추가적인 DXGI 확인\n\nDXGI 개요 - Win32 apps | Microsoft Learn\n\n\n\nCheck Feature Support\n\n{C++}ID3D12Device::CheckFeatureSupport 함수를 사용해 위에선 Multi-Sampling 지원 여부를 점검했는데 이 함수로 여러 기능들을 확인할 수 있음\n\nHRESULT ID3D12Device::CheckFeatureSupport( \n    D3D12_FEATURE Feature,\n    void *pFeatureSupportData,\n    UINT FeatureSupportDataSize\n);\n\nFeature : 지원 여부를 점검할 기능들의 종류\n\n다음과 같은 옵션 중 하나를 지정해야 됨\n{C++}D3D12_FEATURE_D3D12_OPTIONS : Direct3D 12의 여러 기능\n{C++}D3D12_FEATURE_ARCHITECTURE : 하드웨어 아키텍처 기능들\n{C++}D3D12_FEATURE_FEATURE_LEVELS : Feature Levels (기능 버전?)\n{C++}D3D12_FEATURE_FORMAT_SUPPORT : 주어진 Texture 형식에 대한 기능들 (ex: 해당 형식을 렌더 대상으로 사용할 수 있는지, Blender 적용 가능한지 등)\n{C++}D3D12_FEATURE_MULTISAMPLE_QUALITY_LEVELS : Multi-Sample 기능\n\n\npFeatureSupportData : Feature의 지원 정보가 설정될 구조체를 가리키는 포인터\n\n구조체의 구체적인 형식은 Feature 매개변수에 지정한 값에 따라 다름\nFeature에 지정한 옵션에 따라 해당 옵션의 객체를 가리키는 포인터를 넣어줘야 함\nex) {C++}D3D12_FEATURE_MULTISAMPLE_QUALITY_LEVELS로 Feature를 설정했다면 {C++}D3D12_FEATURE_DATA_MULTISAMPLE_QUALITY_LEVELS 객체를 만들어 넣어줘야 함\n\n\nFeatureSupportDataSize : pFeatureSupportData 매개변수로 전달한 구조체의 크기\n이 {C++}ID3D12Device::CheckFeatureSupport 함수로 지원 여부를 점겅할 수 있는 기능들은 이외에도 아주 많은데 그중 다수는 고급 기능으로 나중에 SDK 문서를 확인\n아래의 코드는 이 함수를 사용하는 방법 예시\n\ntypedef struct D3D12_FEATURE_DATA_FEATURE_LEVELS {\n\tUINT NumFeatureLevels;\n\tconst D3D_FEATURE_LEVEL *pFeatureLevelsRequested;\n\tD3D_FEATURE_LEVEL MaxSupportedFeatureLevel;\n} D3D12_FEATURE_DATA_FEATURE_LEVELS;\n \n// D3D 11 기능을 가장 먼저 점검하고 마지막으로 D3D 9.3 기능 지원을 확인\nD3D_FEATURE_LEVEL featureLevels[3] = {\n\tD3D_FEATURE_LEVEL_11_0,\n\tD3D_FEATURE_LEVEL_10_0,\n\tD3D_FEATURE_LEVEL_9_3\n};\n \nD3D12_FEATURE_DATA_FEATURE_LEVELS featureLevelsInfo;\nfeatureLevelsInfo.NumFeatureLevels = 3;\nfeatureLevelsInfo.pFeatureLevelsRequested = featureLevels;\nmd3dDevice-&gt;CheckFeatureSupport(\n\tD3D12_FEATURE_FEATURE_LEVELS,\n\t&amp;featureLevelsInfo,\n\tsizeof(featureLevelsInfo)\n);\n\nFeature Level은 NumFeatureLevels로 어떤걸 지원하는지 확인할 수 있음\nMulti-Sample의 경우 NumQualityLevels로 확인\n\nResidency\n\n복잡한 게임은 Texture, 3차원 Mesh 등 수많은 자원을 사용함 그런데 이 자원들이 항상 GPU에 필요하지는 않음\nDirect3D 12에서는 자원을 GPU 메모리로부터 내림으로써({C++}Evict()), 그리고 필요하면 다시 GPU에 올림으로써({C++}MakeResident())  자원의 Residency를 관리\n\nResidency는 간단하게 말해 자원이 GPU 메모리에 들어 있는지의 여부를 의미\n\n\nResidency 관리의 핵심은 사용하는 GPU 메모리의 양을 최소화하는 것\n\n전체 게임에 필요한 자원들을 모두 GPU 메모리에 담지 못할 수 있고 다른 응용 프로그램에서 GPU 메모리를 사용해야 할 수 있으므로 관리가 꼭 필요함\n성능 측면에서 주의할 점은 같은 자원을 짧은 시간에 GPU 메모리에 넣었다 뺐다 하는 상황은 비용이 발생하기에 피해야 함\n\n이상적으로는 한동안 사용하지 않을 자원들만 GPU 메모리에서 내려야 함\nex) 게임의 레벨이나 지역이 바뀌는 시점에 필요없는 자원 내리기\n\n\n\n\n기본적으로 자원을 생성하면 자원이 GPU 메모리에 입주하며, 파괴되면 메모리에서 나가는데 직접 제어할 수도 있음\n\nHRESULT ID3D12Device::MakeResident(\n\tUINT NumObjects,\n\tID3D12Pageable *const *ppObjects\n);\n \nHRESULT ID3D12Device::Evict(\n\tUINT NumObjects,\n\tID3D12Pageable *const *ppObjects\n);\n\n첫 번째 매개변수는 배열에 들어있는 자원들의 개수이고 두번째 매개변수는 ID3D12Pageable 자원들의 배열\n단순함과 프로그램이 작은 경우 상주성을 직접 관리하지 않을 수도 있음\n\n추가정보는 문서를 확인\nResidency - Win32 apps | Microsoft Learn\n\n\n"},"content/Projects/JEngine---DX12/DirectX12/엔진-개발-04---CPU와-GPU의-상호작용---DirectX12":{"slug":"content/Projects/JEngine---DX12/DirectX12/엔진-개발-04---CPU와-GPU의-상호작용---DirectX12","filePath":"content/Projects/JEngine - DX12/DirectX12/엔진 개발 04 - CPU와 GPU의 상호작용 - DirectX12.md","title":"엔진 개발 04 - CPU와 GPU의 상호작용 - DirectX12","links":[],"tags":["CPP","DirectX12"],"content":"\nCPU와 GPU를 모두 사용해 최적의 성능을 얻으려면 병렬로 사용하지만 중간중간 동기화도 필요함\n\n이때 동기화는 병렬성을 망치기에 최소화해야 함\n\n\n\nCommand Queue와 Command List\n\nGPU에는 Command Queue가 있고 CPU는 렌더링 Command들을 Command List를 만들어 API를 통해 Queue에 제출함\n\n중요한 점은 이 명령들을 GPU가 즉시 실행하는건 아니고 처리할 준비가 되어야지 실행되기 시작함\n즉, GPU가 이전에 제출된 명령들을 처리하느라 바쁘면 명령들은 Queue에 그냥 남아있음\n\nCPU가 명령을 Queue에 제출하면 GPU가 Queue에서 명령을 뽑아서 처리\n\n\n\n\nCommand Queue가 비면 GPU가 놀게되고, 꽉 차있으면 GPU가 명령을 처리해 자리가 생길때까지 CPU가 놀게 됨\n\n두 상황 모두 좋지 않고 최대한 CPU와 GPU가 쉬지 않도록 해줘야 함\n\n\n\nCommand Queue 생성\n\n{C++}ID3D12CommandQueue : Direct3D 12의 Command Queue를 대표하는 Interface\n\n{C++}D3D12_COMMAND_QUEUE_DESC 구조체를 생성해 설정한 다음 {C++}CreateCommandQueue()를 호출해 {C++}ID3D12CommandQueue를 생성함\n\n\n\nMicrosoft::WRL::ComPtr&lt;ID3D12CommandQueue&gt; mCommandQueue;\nD3D12_COMMAND_QUEUE_DESC queueDesc = {};\nqueueDesc.Type = D3D12_COMMAND_LIST_TYPE_DIRECT;\nqueueDesc.Flags = D3D12_COMMAND_QUEUE_FLAG_NONE;\nThrowIfFailed(md3dDevice-&gt;CreateCommandQueue(&amp;queueDesc, IID_PPV_ARGS(&amp;mCommandQueue)));\n\n#define IID_PPV_ARGS(ppType) __uuidof(**(ppType)), IID_PPV_ARGS_Helper(ppType)이 여기서 사용된 {C++}IID_PPV_ARGS()\n\n__uuidof(**(ppType))은 (**(ppType))의 COM Interface ID로 평가되는데, 위의 예시에서 ID는 {C++}ID3D12CommandQueue임\n보조 함수 IID_PPV_ARGS는 ppType을 void**로 Casting함\nDirectX 12 API에는 생성하고자 하는 Interface의 COM ID와 void**를 받는 함수들이 많기 때문에, 이 MACRO들은 자주 사용됨\n즉, COM ID와 void**를 인자로 사용할 수 있게 해줌\n\n\nCommandList에는 {C++}ID3D12CommandAllocator 형식의 메모리 할당자가 하나 연관되는데 Command들은 이 메모리에 저장됨\n{C++}ExecuteCommandLists()로 CommandList를 제출하면, CommandQueue는 메모리 할당자에 담긴 Command들을 참조함\n\nHRESULT ID3D12Device::CreateCommandAllocator(\n\tD3D12_COMMAND_LIST_TYPE type,\n\tREFIID riid,\n\tvoid **ppCommandAllocator\n);\n\nCommand 메모리는 위의 함수를 사용해 할당해줌\ntype : 메모리 할당자와 연관시킬 수 있는 CommandList의 종류, 흔히 2 종류를 사용\n\n{C++}D3D12_COMMAND_LIST_TYPE_DIRECT : GPU가 직접 실행하는 CommandList\n{C++}D3D12_COMMAND_LIST_TYPE_BUNDLE : Bundle을 나타내는 CommandList로 CommandList를 만드는데에는 CPU의 부담이 어느정도 있기 때문에, Direct3D 12는 일련의 Command들을 소위 Bundle(묶음) 단위로 기록할 수 있는 최적화 수단을 제공\n\nBundle을 추가하면 Driver는 렌더링 도중에 실행이 최적화되도록 Bundle의 Command들을 전처리함\nProfile을 통해 특정 Command List를 구축하는데 시간이 오래 걸리는걸 발견했다면, 이런 Bundle을 사용해 최적화를 고려해야 함\n\n무조건 사용하지는 말고 성능상의 이득이 명확한 경우에만 사용\n\n\n\n\n\n\nriid : 생성하고자 하는 ID3D12CommandAllocator Interface의 COM ID\nppCommandAllocator : 생성된 명령 할당자를 가리키는 포인터 (출력 매개변수)\nriid와 ppCommandAllocator는 위에서 설명한 IID_PPV_ARGS()로 한 번에 설정할 수 있음\n\n{C++}ThrowIfFailed(md3dDevice-&gt;CreateCommandAllocator(D3D12_COMMAND_LIST_TYPE_DIRECT, IID_PPV_ARGS(mDirectCmdListAlloc.GetAddressOf())));\n\n\n\nCommandList 생성\nHRESULT ID3D12Device::CreateCommandList(\n\tUINT nodeMask,\n\tD3D12_COMMAND_LIST_TYPE type,\n\tID3D12CommandAllocator *pCommandAllocator,\n\tID3D12PipelineState *pInitialState,\n\tREFIID riid,\n\tvoid **ppCommandList\n);\n\nnodeMask : GPU가 하나인 시스템에서는 0으로 설정\n\nGPU가 여러개라면 이 CommandList에 연관시킬 물리적 GPU 어댑터 노드들을 지정하는 bitmask 값을 설정\nGPU 어댑터 노드 개수는 {C++}GetNodeCount()로 알아낼 수 있음\n\n\ntype : CommandList 종류\n\n{C++}D3D12_COMMAND_LIST_TYPE_DIRECT  or {C++}D3D12_COMMAND_LIST_TYPE_BUNDLE\n\n\npCommandAllocator : 생성된 CommandList에 연결시킬 메모리 할당자\n\nCommandList와 메모리 할당자의 type이 일치해야 함\n\n\npInitialState : CommandLIst의 초기 파이프라인 상태를 지정\n\nBundle의 경우 초기화 목적으로 쓰이며 실제 렌더링 명령은 없는 CommandList의 경우에는 Null을 지정해도 됨\n\n\nriid : 생성하고자 하는 CommandList에 해당하는 {C++}ID3D12CommandList Interface의 COM ID\nppCommandList : 생성된 CommandLIst를 가리키는 포인터 (출력)\n한 Memory Allocator를 여러 CommandList에 연관시켜도 되지만, Command들을 여러 CommandList에 동시에 기록할 수는 없음\n\n즉, 현재 Command들을 추가하는 CommandList을 제외한 모든 CommandList은 Close되어 있어야 함\n이렇게 해야 한 CommandList에 모든 Command들이 바로 옆에 인접해서 저장됨\n\n\nCommandList을 생성하거나 재설정하면 CommandList은 Open 상태가 되기에 주의해야 함\n\n따라서, 같은 메모리 할당자로 두 CommandList를 연달아 생성하면 오류가 발생함\n\n\n\nCommandList의 Command를 Queue에 추가하는 방법\n\nID3D12CommandQueue를 사용해 Command List에 있는 명령들을 대기열에 추가하는 함수\n\nvoid ID3D12CommandQueue::ExecuteCommandLists(\n\t// 배열에 있는 명령 목록들의 개수\n\tUINT Count,\n\t// 명령 목록들의 배열의 첫 원소를 가리키는 포인터\n\tID3D12CommandList *const *ppCommandLists\n);\n\nCommandList들은 배열의 첫 원소부터 차례로 실행됨\n{C++}ID3D12CommandLists가 CommandList의 Interface인데 실제 그래픽 작업을 위한 CommandList는 이 Interface를 상속하는 {C++}ID3D12GraphicsCommandList라는 Interface를 사용함\n\n{C++}ID3D12GraphicsCommandList Interface에는 명령들을 CommandList에 추가하는 여러 함수들이 있음\nex) 아래 코드는 viewport를 설정하고 RenderTargetView를 지우고, 그리기 호출을 실행하는 명령들을 추가하는 과정\n\n\n\n// mCommandList는 ID3D12CommandList 포인터\nmCommandList-&gt;RSSetViewports(1, &amp;mScreenViewport);\nmCommandList-&gt;ClearRenderTargetView(mBackBufferView, Colors::LightSteelBlue, 0, nullptr);\nmCommandList-&gt;DrawIndexedInstanced(36, 1, 0, 0, 0);\n\n이 코드는 그냥 Command를 CommandList에 기록하기만 하고 나중에 {C++}ExecuteCommandLists()를 호출해야 명령들이 CommandQueue에 추가되고 GPU가 나중에 여기서 Command를 뽑아서 실행함\n\n// CommandLIst를 닫아 기록을 끝냄\nmCommandList-&gt;Close();\n\n이 함수를 호출해 명령들의 기록이 끝났음을 반드시 알려줘야 함\n\nHERESULT ID3D12CommandList::Reset(\n\tID3D12CommandAllocator *pAllocator,\n\tID3D12PipelineState *pInitialstate\n);\n\n이 {C++}Reset()을 사용해서 CommadList에 연결된 메모리에 새로운 명령들을 기록하는데 재사용할 수 잇게 됨\n\nCommandList를 처음 생성했을때와 같은 상태로 만들어줌\n즉, CommandList를 해제하고 새로 할당하는 번거로움 없이 메모리를 재사용할 수 있는 것\n\n\nCommandList를 재설정해도 CommandQueue에 있는 Command들에는 영향을 미치지 않음\n\nCommandQueue가 참조하는 Command들은 연관된 CommandAllocator의 메모리에 여전히 남아있기 때문\n\n\n하나의 Frame의 렌더링 명령들을 GPU에 제출한 후에는, CommandAllocator의 메모리를 다음 Frame을 위해 재사용해야 할 것이므로 {C++}Reset()을 사용\n\n{C++}std::vector::clear와 비슷한 개념으로 Vector의 크기가 0이 되지만 현재 Capacity는 변하지 않음\n그러나 CommandQueue가 메모리 할당자 안의 자료를 참조하고 있을 수 있으므로 GPU가 CommandList에 담긴 모든 명령을 실행했음이 확실해지기 전까지는 재설정하지 말아야 함\n\n\n\nCPU-GPU 동기화\n\n두 개의 처리 장치가 병렬로 실행되면 여러가지 동기화 문제가 발생함\n\nCPU에서 어떤 물체를 그리기 위해 위치 정보를 참조하는 그리기 명령을 CommandQueue에 추가함\n그런데 CommandQueue에 추가하는 연산은 CPU의 실행을 차단하지 않으므로 계속해서 다음 단계로 넘어가는데 만약 GPU가 해당 물체를 그리기 전에 CPU가 새로운 위치를 갱신해 기존의 위치가 덮어씌워지면 원래 의도했던 위치에 물체가 그려지지 않게 됨\n\n\n이런 문제의 해결책 하나는 GPU가 CommandQueue의 Command들 중 특정 지점까지의 모든 명령을 다 처리할때까지 CPU를 기다리게 하는 것\n\n이걸 CommandList을 비운다 또는 방출한다(flush)라고 함\n이때 필요한 것이 Fence라고 부르는 객체\n\n\n\nFence\n\n{C++}ID3D12Fence Interface인 Fence는 GPU와 CPU의 동기화를 위한 수단으로 사용됨\n\nHRESULT ID3D12Device::CreateFence(\n\tUINT64 InitialValue,\n\tD3D12_FENCE_FLAGS Flags,\n\tREFIID riid,\n\tvoid **ppFence\n);\n\n예시\n\nThrowIfFailed(md3dDevice-&gt;CreateFence(0, D3D12_FENCE_FLAG_NONE, IID_PPV_ARGS(&amp;mFence)));\n\nFence 객체는 UINT64 값 하나를 관리함\n\n이 값은 시간상의 특정 Fence 지점을 식별하는 정수\nDirectX12 교재에서는 처음 Fence가 하나도 없을땐 이 값을 0으로 두고, 새 Fence를 만들때마다 이 값을 1씩 증가시킴\n\n\n\nvoid D3DApp::FlushCommandQueue()\n{\n\t// 현재 Fence 지저까지의 Command들을 표시하도록 Fence  값을 증가\n    mCurrentFence++;\n \n    // 새 Fence 지점을 설정하는 명령(Signal)을 CommandQueue에 추가\n    // 지금은 GPU timeline 상에 있으므로, 새 Fence 지점은 GPU가 이 Signal()\n    // 명령까지의 모든 명령을 처리하기 전까지는 설정되지 않음\n    ThrowIfFailed(mCommandQueue-&gt;Signal(mFence.Get(), mCurrentFence));\n \n\t// GPU가 이 Fence 지점까지의 명령들을 완료할 때까지 기다림\n    if(mFence-&gt;GetCompletedValue() &lt; mCurrentFence)\n\t{\n\t\tHANDLE eventHandle = CreateEventEx(nullptr, false, false, EVENT_ALL_ACCESS);\n \n        // GPU가 현재 Fence 지점에 도달헀으면 Event를 발동 \n        ThrowIfFailed(mFence-&gt;SetEventOnCompletion(mCurrentFence, eventHandle));\n \n        // GPU가 현재 Fence 지점에 도달했음을 뜻하는 Event를 기다림\n\t\tWaitForSingleObject(eventHandle, INFINITE);\n        CloseHandle(eventHandle);\n\t}\n}\n\n이 함수는 Fence를 이용해서 CommandQueue를 비우는 방법\n이 함수를 매 Frame이 끝나거나 시작할때 사용해 CommandQueue를 비워주면 되지만 이상적인 해결책은 아님\n\nGPU의 작업이 끝날때까지 CPU가 기다려야 하기 때문\n더 좋은 방법은 추후 설명\n\n\nCommandQueue를 비우는 시점에는 제약이 거의 없음\n\n특히, 한 Frame에서 딱 한 번만 비워야 하는 것은 아님 (여러번 비울 수 있음)\nex) 초기화를 위한 GPU 명령들이 있다면, 먼저 초기화 명령들을 비운 후에 주 렌더링 Loop로 진입하면 2번 Flush하는 것\n\n\n위에서 말한 오류를 해결하려면 모든 GPU 명령이 실행되었음이 확실해진 이후에 CommandAllocator를 재설정하려면, CommandQueue를 비운 후에 CommandAllocator를 재설정하면 됨\n\nResource Transition\n\n렌더링 파이프라인에서는 GPU가 한 State에서 한 Resource에 Write하고 다른 State에서 같은 Resource를 Read하는 식으로 사용하는 경우가 많음\n그런데 GPU의 Write가 끝나지 않았거나 Write하지도 않았는데 Read하려고 하면 문제가 생김\n\n이를 Resource Hazard라고 부르기도 하는데 병렬처리의 가장 대표적인 위험 상황\n\n\n이 문제를 해결하기 위해 Direct3D는 Resource들에 State를 부여함\n\n새로 생성된 Resource는 Default State로 시작\n\n\n임의의 State Transition을 Direct3D에게 보고하는 것은 전적으로 CPU의 몫\n\n그래서 GPU는 State를 Transition하고 Resrouce Hazard를 방지하는데 필요한 일들을 자유롭게 진행할 수 있음\nex) Texture 자원에 Write할때는 RenderTarget으로 설정하고 이후 Texture를 Read할때는 ShaderResource로 Transition함\n\n\nResource Transition을 CPU가 Direct3D에 보고함으로써, GPU는 Resource Hazard를 피하는데 필요한 조치를 진행할 수 있음\n\nex) Write가 완도되길 기다린 후 Read를 시도하기\n\n\nTransition을 프로그램에게 맡긴건 성능 때문으로 프로그래머는 이런 전이가 언제 필요한지 알고 있는데 이걸 자동으로 추적하면 성능에 부담이 생기기 떄문\n\nResource Transition 방법\n\nTransition Resource Barrier들의 배열을 설정해서 Resource Transition을 지정할 수 있음\n배열을 사용하는 덕분에, 한 번의 API 호출로 여러 개의 Resource를 Transition할 수 있음\n\n{C++}D3D12_RESOURCE_BARRIER_DESC 구조체로 설정\n\n\n\nstruct CD3DX12_RESOURCE_BARRIER : public D3D12_RESOURCE_BARRIER\n{\n   ...\n    static inline CD3DX12_RESOURCE_BARRIER Transition(\n        _In_ ID3D12Resource* pResource,\n        D3D12_RESOURCE_STATES stateBefore,\n        D3D12_RESOURCE_STATES stateAfter,\n        UINT subresource = D3D12_RESOURCE_BARRIER_ALL_SUBRESOURCES,\n        D3D12_RESOURCE_BARRIER_FLAGS flags = D3D12_RESOURCE_BARRIER_FLAG_NONE)\n    {\n        CD3DX12_RESOURCE_BARRIER result;\n        ZeroMemory(&amp;result, sizeof(result));\n        D3D12_RESOURCE_BARRIER &amp;barrier = result;\n        result.Type = D3D12_RESOURCE_BARRIER_TYPE_TRANSITION;\n        result.Flags = flags;\n        barrier.Transition.pResource = pResource;\n        barrier.Transition.StateBefore = stateBefore;\n        barrier.Transition.StateAfter = stateAfter;\n        barrier.Transition.Subresource = subresource;\n        return result;\n    }\n    ...\n\nd3dx12.h에 정의되어 있는 보조 함수들을 사용해 주어진 자원과 이전, 이후 State에 해당하는 Transition Resource Barrier 구조체를 생성\n\n{C++}CD3DX12_RESOURCE_BARRIER가 {C++}D3D12_RESOURCE_BARRIER_DESC를 상속하고 거기에 여러 편의용 함수들을 추가한 일종의 확장 버전임\n\n\nDirect3D 12의 구조체들은 대부분에는 이런 편의용 확장 버전들이 존재하는데 {C++}CD3DX12_로 시작하는 확장 버전들은 모두 d3dx12.h에 정의되어 있음\n\n이 헤더 파일은 공식 DirectX12 SDK의 일부가 아니라서 Microsoft 사이트에서 따로 다운받아 사용해야 함\n\n\n\n\tmCommandList-&gt;ResourceBarrier(1, &amp;CD3DX12_RESOURCE_BARRIER::Transition(CurrentBackBuffer(),\n\t\tD3D12_RESOURCE_STATE_PRESENT, D3D12_RESOURCE_STATE_RENDER_TARGET));\n\n확장 버전 사용 예시로 화면에 표시할 이미지를 나타내는 Texture 자원을 Presentation State에서 RenderTarget으로 Transition하고 있음\n이때 Transition Reosurce Barrier가 CommandList에 추가되고 있음\n\nTransition Resource Barrier라는 것을 GPU에게 Resource의 State가 Transition됨을 알려주는 하나의 명령이라고 생각하면 됨\n\n\nCommand을 통해서 Resource의 Transition State를 알려주기에 GPU는 이후의 명령들을 실행할때 위험 상황을 피하는데 필요한 단계들을 수행함\n\nCommandList를 이용한 Multi-Thread 활용\n\nDirectX12는 Multi-Thread를 효율적으로 활용할 수 있도록 설계되어 있음\nCommandList의 설계는 Direct3D가 Multi-Thread 적용의 장점을 취하는 한 방법\n\n물체가 많은 큰 장면을 다룰때, 장면 전체를 하나의 CommandList로 그리려면 CommandList를 구축하느데 시간(CPU 시간)이 오래 걸림\n\n\n해결책은 여러 개의 CommandList을 병렬로 구축하는 것\n\nex) Thread 4개를 띄워서 각자 하나의 CommandLIst를 구축하게 하면, 전체적인 시간이 25% 줄어듬\n\n\nCommandList 생성에 Multi-Thread 적용시 주의할 점\n\n\n\nCommandList는 Free-Threaded 모형을 따르지 않는다\n\n\n보통의 경우 여러 Thread가 같은 CommandList를 공유하지 않으며, 그 Method들을 동시에 호출하지 않는다\n따라서, 일반적으로 각 Thread는 각자 자신만의 CommandList를 가지게 됨\n\n\n\n\nCommandAllocator도 Free-Threaded가 아니다\n\n\n보통의 경우 여러 Thread가 같은 CommandAllocator를 공유하지 않으며, 그 method들을 동시에 호출하지 않음\n일반적으로 각 Thread는 각자 자신만의 CommandAllocator를 가지게 됨\n\n\n\n\nCommandQueue는 Free-Threaed 모형을 따른다\n\n\n여러 Threads가 같은 CommandQueue에 접근해 그 Method들을 동시에 호출할 수 있다\n특히, Thread들이 각자 자신이 생성한 CommandList을 동시에 CommandQueue에 제출할 수 있다.\n\n\n\n\n성능상의 이유로, 프로그램은 동시에 기록할 수 있는 CommandList들의 최대 개수를 반드시 초기화 시점에서 설정해야 한다.\n\n\n\n\n지금은 Multi-Thread를 적용하지 않겠지만 추후에 확장\n"},"content/Projects/JEngine---DX12/DirectX12/엔진-개발-05---DirectX12-초기화-및-Log-시스템-업데이트":{"slug":"content/Projects/JEngine---DX12/DirectX12/엔진-개발-05---DirectX12-초기화-및-Log-시스템-업데이트","filePath":"content/Projects/JEngine - DX12/DirectX12/엔진 개발 05 - DirectX12 초기화 및 Log 시스템 업데이트.md","title":"엔진 개발 05 - DirectX12 초기화 및 Log 시스템 업데이트","links":[],"tags":["CPP","DirectX12"],"content":"Log 시스템\n\nLog 시스템에 LogLevel을 추가해 상황별로 Log를 출력할 수 있도록 변경\nMessage를 출력하기 전에 어떤 Level의 Message인지 추가로 출력할 수 있도록 수정했습니다.\n\nenum class LogLevel { \n    Info, \n    Warning, \n    Error,    \n    Debug \n};\n \nclass Logger {\n...\n\tstd::string getLogLevelString(LogLevel level) {\n        switch (level) {\n        case LogLevel::Info:\n            return &quot;[INFO]&quot;;\n        case LogLevel::Warning:\n            return &quot;[WARNING]&quot;;\n        case LogLevel::Error:\n            return &quot;[ERROR]&quot;;\n        case LogLevel::Debug:\n            return &quot;[DEBUG]&quot;;\n        default:\n            return &quot;[UNKNOWN]&quot;;\n    }\n\t\n}\n\nDirectX와 Window에서는 여러 함수의 오류를 {C++}HRESULT 형식으로 돌려주기 떄문에 이 값을 받아서 간단하게 어디에서 문제를 일으키고 있는지 알 수 있도록 Log를 출력하는 Helper 함수를 하나 더 만들었습니다.\n\n여기서는 C++ 20부터 지원하는 #include &lt;source_location&gt;을 활용해서 어느 파일의 어떤 함수의 어디 Line에서 문제를 일으키는지 위치를 찾아 사용합니다.\n\n\n\ninline void ThrowIfFailed(\n    HRESULT hr, \n    const std::source_location&amp; location = std::source_location::current()\n) {\n    if (FAILED(hr)) {\n        std::string errorMsg = std::format(\n            &quot;DirectX Error\\n&quot;\n            &quot;  File: {}\\n&quot;\n            &quot;  Line: {}\\n&quot;\n            &quot;  Function: {}\\n&quot;\n            &quot;  HRESULT: 0x{:08X}&quot;,\n            location.file_name(), \n            location.line(),\n            location.function_name(),\n            static_cast&lt;unsigned&gt;(hr)\n        );\n        LogError(&quot;{}&quot;, errorMsg);\n        throw std::runtime_error(errorMsg);\n    }\n}\nDirectX12 초기화\n\nDirectX의 초기화는 DirectX의 Device를 생성하는 것으로 시작합니다.\n이 Device를 통해서 GPU에서 메모리를 할당받거나, GPU와 관련된 것들을 생성 및 관리를 할 수 있습니다.\n\nDevice 생성\n\n이 Device 생성 함수에서 Device 외에도 Fence, MSAA, DescriptorHeap을 전부 생성하고 있는데 나중에 Refactoring을 통해 각 기능을 분리해줄 예정입니다.\n\nvoid Context::createDevice() {\n    UINT dxgiFactoryFlags = 0;\n \n#if defined(DEBUG) || defined(_DEBUG)\n    {\n        // Enable the D3D12 debug layer.\n        ComPtr&lt;ID3D12Debug&gt; debugController;\n        ThrowIfFailed(::D3D12GetDebugInterface(IID_PPV_ARGS(&amp;debugController)));\n        debugController-&gt;EnableDebugLayer();\n \n        // Enable DXGI debug layer\n        dxgiFactoryFlags = DXGI_CREATE_FACTORY_DEBUG;\n \n        LogInfo(&quot;D3D12 Debug Layer enabled for Debug build.&quot;);\n    }\n#endif\n    // CreateDXGIFactory2 권장 (DirectX 12 표준)\n    ThrowIfFailed(::CreateDXGIFactory2(dxgiFactoryFlags, IID_PPV_ARGS(&amp;dxgiFactory_)));\n\t...\n\nDevice를 생성할때 DXGIFactory도 생성해주는데 나중에 이걸 통해서 SwapChain이나 Adapter를 생성하는데 사용됩니다.\n\n{C++}ComPtr&lt;IDXGIFactory6&gt; dxgiFactory_;\n\n\n디버깅을 위해서 Debugging Layer를 활성화해서 정보를 가져올 수 있도록하고 디버깅이 필요 없다면 비활성화해 속도를 올려줍니다.\n\n    // Try to create hardware device first\n    HRESULT hr = ::D3D12CreateDevice(\n        nullptr,                    // default adapter (하드웨어 GPU)\n        D3D_FEATURE_LEVEL_12_0,     // minimum feature level\n        IID_PPV_ARGS(&amp;device_));\n \n    // Fallback to WARP device if hardware device creation failed\n    if (FAILED(hr))\n    {\n        LogWarning(&quot;Hardware device creation failed. Falling back to WARP device (software rendering).&quot;);\n        \n        ComPtr&lt;IDXGIAdapter&gt; warpAdapter; // Display Adapter\n        ThrowIfFailed(dxgiFactory_-&gt;EnumWarpAdapter(IID_PPV_ARGS(&amp;warpAdapter)));\n \n        ThrowIfFailed(::D3D12CreateDevice(\n            warpAdapter.Get(),          // WARP adapter\n            D3D_FEATURE_LEVEL_12_0,\n            IID_PPV_ARGS(&amp;device_)));\n        \n        LogInfo(&quot;WARP device created successfully.&quot;);\n    }\n    else\n    {\n        LogInfo(&quot;Hardware device created successfully.&quot;);\n    }\n\nDevice를 생성해주는데 이 Device를 통해 GPU에서 메모리를 할당받는 등 물리적인 GPU에 접근할 수 있습니다.\n만약 GPU가 없다면 WARP를 생성하는데 MS에서 제공하는 소프트웨어 렌더러로 CPU를 통한 렌더링을 지원해줍니다.\n\nGPU보다는 느리겠지만 DirectX의 기능을 지원해주기 때문에 우선적으로 GPU Device를 생성해보다가 없다면 CPU Device를 생성해줍니다.\n\n\n\nFence 생성\n\t// CPU와 GPU 간 리소스 동기화를 위한 Fence 생성\n    ThrowIfFailed(device_-&gt;CreateFence(0, D3D12_FENCE_FLAG_NONE, IID_PPV_ARGS(&amp;fence_)));\n    LogInfo(&quot;Fence created for CPU-GPU synchronization.&quot;);\n\nFence를 생성해주는데 이 Fence는 CPU와 GPU의 동기화를 위한 것으로 CPU와 GPU의 병렬처리를 위한 것입니다.\nC++에서 Multi-Thread를 하는것과 같은 문제가 CPU-GPU 병렬처리에서 생길수 있는데 이런 병렬처리에서 생길 수 있는 문제 중 CPU-GPU 병렬 문제를 해결하기 위한 방법입니다.\n\nDescriptor Heap 크기 할당받기\n// Descriptor size for CBV/SRV/UAV\n    rtvDescriptorSize_ = device_-&gt;GetDescriptorHandleIncrementSize(\n        D3D12_DESCRIPTOR_HEAP_TYPE_RTV);\n    dsvDescriptorSize_ = device_-&gt;GetDescriptorHandleIncrementSize(\n        D3D12_DESCRIPTOR_HEAP_TYPE_DSV);\n    cbvSrvUavDescriptorSize_ = device_-&gt;GetDescriptorHandleIncrementSize(\n        D3D12_DESCRIPTOR_HEAP_TYPE_CBV_SRV_UAV);\n    LogInfo(&quot;Descriptor sizes - RTV: {}, DSV: {}, CBV/SRV/UAV: {}&quot;, \n        rtvDescriptorSize_, dsvDescriptorSize_, cbvSrvUavDescriptorSize_);\n\n필요한 Descriptor들의 크기를 미리 조회해서 설정해줍니다.\nGPU마다 Descriptor의 크기가 다를 수 있어서 실행시점에서 알아내줍니다.\nDescriptorHeap들도 생성해주고 있는데 이건 Resource들을 GPU에서 사용하지 위해 Resource에 대한 View를 만들어서 이 View를 통해 사용하는데 이 View를 C++의 {C++}std::vector처럼 모아두는 곳입니다.\n{C++}std::vector를 사용할때 미리 {C++}reserve()를 한 뒤 어떤 Index의 포인터를 받아 온 뒤 나중에 메모리 내용을 작성해주는 방법과 비슷합니다.\n\nMSAA 기능 활성화\n\t// check 4x MSAA quality support\n    D3D12_FEATURE_DATA_MULTISAMPLE_QUALITY_LEVELS msaaQualityLevels;\n    msaaQualityLevels.Format = backBufferFormat_;\n    msaaQualityLevels.SampleCount = 4;\n    msaaQualityLevels.Flags = D3D12_MULTISAMPLE_QUALITY_LEVELS_FLAG_NONE;  \n    msaaQualityLevels.NumQualityLevels = 0;\n    ThrowIfFailed(device_-&gt;CheckFeatureSupport(\n        D3D12_FEATURE_MULTISAMPLE_QUALITY_LEVELS,\n        &amp;msaaQualityLevels, sizeof(msaaQualityLevels)));\n \n    m4xMsaaQuality_ = msaaQualityLevels.NumQualityLevels;\n    if (m4xMsaaQuality_ &gt; 0) \n        ExitWithMessage(&quot;4x MSAA is not supported for the back buffer format!&quot;);\n    LogInfo(&quot;4x MSAA Quality Levels supported: {}&quot;, m4xMsaaQuality_);\n\nMSAA는 Anti-Aliasing의 방법인데 DirectX에서 지원해주는 기능입니다.\n\n\n여기서는 이 기능을 활성화해 초기화하고 있는데 보통 실시간 렌더링에서는 이 기능을 활성화하면 속도가 느리기에 비활성화하고 나중에 Shader를 사용해 Anti-Aliasing을 적용하는 방식을 더 많이 사용합니다.\n\n\n\nCommand Object 생성\n\nCommandQueue, CommandList, CommandAllocator들을 생성해줍니다\n\nvoid Context::createCommandObjects() {\n    // Create Command Queue\n    D3D12_COMMAND_QUEUE_DESC queueDesc = {};\n    queueDesc.Type = D3D12_COMMAND_LIST_TYPE_DIRECT; // Direct Command Queue\n    queueDesc.Flags = D3D12_COMMAND_QUEUE_FLAG_NONE;\n    ThrowIfFailed(device_-&gt;CreateCommandQueue(&amp;queueDesc, IID_PPV_ARGS(&amp;commandQueue_)));\n    LogInfo(&quot;Command Queue created.&quot;);\n \n    // Create Command Allocator\n    ThrowIfFailed(device_-&gt;CreateCommandAllocator(\n        D3D12_COMMAND_LIST_TYPE_DIRECT, // Command Queue의 Type과 동일해야 함\n        IID_PPV_ARGS(commandAllocator_.GetAddressOf())));\n    LogInfo(&quot;Command Allocator created.&quot;);\n \n    ThrowIfFailed(device_-&gt;CreateCommandList(\n        0, // single GPU node\n        D3D12_COMMAND_LIST_TYPE_DIRECT,\n        commandAllocator_.Get(), // Command Allocator와 연결\n        nullptr, // 초기 PSO 없음\n        IID_PPV_ARGS(commandList_.GetAddressOf())));\n    LogInfo(&quot;Graphics Command List created.&quot;);\n \n    // Close Command List to prepare it for reset before recording commands\n    commandList_-&gt;Close();\n    LogInfo(&quot;Command List closed and ready for recording commands.&quot;);\n}\n\nDirectX12에서는 GPU를 사용하기 위해서 Command를 작성해서 GPU에 CommandList를 넘겨주면 나중에 GPU에서 가능할때 알아서 이 명령을 실행합니다.\n이런 명령을 작성하기 위해서 CommandQueue, CommandAllocator, CommandList들을 생성해줍니다.\n\nCommandQueue는\n\n\n"},"content/Projects/JEngine---DX12/DirectX12/엔진-개발-06---Window-초기화":{"slug":"content/Projects/JEngine---DX12/DirectX12/엔진-개발-06---Window-초기화","filePath":"content/Projects/JEngine - DX12/DirectX12/엔진 개발 06 - Window 초기화.md","title":"엔진 개발 06 - Window 초기화","links":[],"tags":["CPP","Windows"],"content":"Window 창 생성\n\nDirectX를 사용하기 위해서 Device 등 초기화를 할때 Window 창의 {C++}HWND 값이 필요합니다.\n\n이전에는 일단 DirectX 초기화 코드 작성을 위해 HWND를 {C++}nullptr로 설정한 뒤 build만 진행했지만 실제로 윈도우 창을 생성해 띄워볼 예정입니다.\n\n\n"},"content/Projects/JEngine---DX12/JEngine-Project":{"slug":"content/Projects/JEngine---DX12/JEngine-Project","filePath":"content/Projects/JEngine - DX12/JEngine Project.md","title":"JEngine Project","links":["content/Projects/JEngine---DX12/DirectX12/엔진-개발-01---프로젝트-초기-설정","content/Projects/JEngine---DX12/DirectX12/엔진-개발-02---Log-시스템","content/Projects/JEngine---DX12/DirectX12/엔진-개발-03---Direct3D","content/Projects/JEngine---DX12/DirectX12/엔진-개발-04---CPU와-GPU의-상호작용---DirectX12","content/Projects/JEngine---DX12/DirectX12/엔진-개발-06---Window-초기화"],"tags":["Engine","Graphics","CPP","DirectX12"],"content":"엔진 개발의 시작\n여태까지 강의를 보고 따라하면서 WinAPI + C++, C++ + DirectX11 조합으로 간단한 렌더러나 엔진은 구현했습니다.\n그런데 이렇게 진행한 대부분의 엔진의 코드는 지금 계속 공부하면서 되돌아보면 간단한 구조로 어느정도 하드코딩되어서 그냥 순차적으로 나열해 구현되어 있는 것 같습니다.\n즉, 진짜 엔진의 구조로 만들어진게 아니라 그냥 순차적으로 코딩해 만들었지만 그냥 Singleton, Composition 등 약간의 디자인 패턴과 클래스로 나눠 두었을 뿐 추상화 작업은 거의 이루어지지 않았습니다.\n그런데 이번에 HongLab의 Real-Time Rendering With Vulkan 강의를 듣고 확장 가능한 엔진을 어떻게 만들면 좋을지 알았습니다.\n여태 공부한 그래픽스 이론과 이번에 공부한 기본적인 엔진 구조로 확장 가능한 엔진을 만드는 프로젝트를 진행해보려고 합니다.\n개인적인 포트폴리오이자 앞으로 새로운걸 계속 배우면서 배운 내용을 추가적으로 적용할 수 있게 만들 계획입니다.\n이번에 사용할 그래픽스 API는 DirectX 12를 공부하면서 프로젝트를 진행할 예정입니다.\nReference\n공부한 내용을 바탕으로 코드를 참고하고 AI를 활용\n\nReal-Time Rendering with Vulkan\nAlgorithm1\nAlgorithm 2\nHongLab Graphics 1 ~ 4\n\nGraphics 1\nGraphics 2\nGraphics 3\nGraphics 4\n\n\n이종 병렬 컴퓨팅 - Cuda 입문\n게임 프로그래머 입문 올인원\n게임 수학의 이해\n이득우의 게임 수학\nC++을 활용해 유니티처럼 엔진만들기\nDirectX 12 책\n\nProject - DirectX12\n\n엔진 개발 01 - 프로젝트 초기 설정 - 프로젝트 생성\n엔진 개발 02 - Log 시스템 - Logger 클래스\n엔진 개발 03 - Direct3D - Direct3D를 위해 알아야하는 것들\n\nCOM, Device, Resource와 Descriptor, DXGI, 지원하는 기능을 확인하는 방법\n\n\n엔진 개발 04 - CPU와 GPU의 상호작용 - DirectX12 - DirectX에서 CPU와 GPU의 병렬 처리\n\nVulkan에서는 Barrier, Fence, Semaphore로 동기화와 병렬 처리를 관리했음\nDirectX 12에서 CPU-GPU 병렬 처리과 동기화 개념\n\n여기서는 Barrier와 Fence만 설명\n\n\nCommand, CommandList, CommandQueue\n\n생성 방법과 간단한 사용법\n\n\nResource Transition\n\n같은 자원을 다른 방식으로 사용\n\n\n\n\n엔진 개발 06 - Window 초기화 - 초기화\n"},"content/Projects/Project-설정법/VS2022-프로젝트-설정":{"slug":"content/Projects/Project-설정법/VS2022-프로젝트-설정","filePath":"content/Projects/Project 설정법/VS2022 프로젝트 설정.md","title":"VS2022 프로젝트 설정","links":[],"tags":["Project"],"content":"프로젝트 구조\n\n게임 엔진 프로젝트로써 Application이 Window 창의 띄우는 가장 중심이 되는 프로젝트가 됩니다.\nEngine, Math, Renderer 프로젝트는 Static Library로써 각각 핵심 기능을 가지고 있고 Application에서 Library의 기능을 조합해 사용합니다.\n컴파일 시간 개선\nMulti-processor Compilation 설정정\n\n프로젝트 규모가 커지면 컴파일 하는데 시간이 오래걸리게 됩니다. 그러면 컴파일 시 멀티 프로세서 사용을 True로 설정하면 병렬적으로 컴파일하기에 컴파일 시간이 줄어들게 됩니다.\nPrecompiled Header\n\nPCH (Precompiled Header)를 사용하면 컴파일 시간을 줄일 수 있습니다.\npch는 Precompiled Header로 미리 컴파일된 헤더입니다.\npch는 최대한 변경되지 않을 다수의 헤더를 모아서 한 번 build해 놓고 변경사항이 없을 때는 build하지 않는 파일로 컴파일 속도가 빨라지나 변경사항이 자주 일어나면 전체를 다시 Build하기에 속도가 저하됩니다.\n전처리 단계에서 실행되며 cpp의 최상단에 올라갑니다.\n일반적으로 pch라는 이름을 사용하지만 이름은 바꿀 수 있습니다.\n\n\n\npch 클래스를 생성해줍니다.\n\n\n\npch 설정\n\npch.cpp의 설정창을 열어 Precompiled Header 옵션에서 Precompiled Header를 생성(Create)하는 옵션을 설정하고 헤더 파일의 이름을 pch.h로 설정해줍니다.\n\npch를 설정할 프로젝트의 설정창을 열어 Precompiled Header 옵션에서 Precompiled Header를 사용(Use)으로 바꿔 생성한 헤더를 사용하도록 합니다. 헤더 파일은 cpp의 설정창에서 사용한 이름과 동일하게 설정해주면 pch를 사용할 수 있습니다.\n\n\npch.h에서 사용할 헤더 include\n\n자주 사용하면서 최대한 변경되지 않을 다수의 헤더를 pch에서 include해줍니다.\n보통 std, window 헤더들인 외부 라이브러리 헤더들을 include 해줍니다.\n새로 만든 library의 헤더들도 자주 변경하지 않으면서 많은 곳에 사용하면 추가해 줍니다.\n\n\n\n\n설정한 pch 사용법\n\n설정한 pch는 보통 cpp 파일 가장 처음에 include해 pch에서 include한 헤더들을 사용하도록 합니다.\n\n\n폴더 설정\n\n프로젝트 구성할 때 추가적으로 폴더를 생성한 뒤 프로젝트에서 이 폴더들을 설정해주면 좀 더 정리가 가능해집니다.\n\nIntermediate : 컴파일의 중간 결과물 (obj 파일등이 들어가도록 설정)\nLibraries : static library 프로젝트의 결과물 (h 파일들과 lib, dll 파일들)\n\nExternal : 외부에서 다운받은 Library 저장 (FMod 등)\nInlucde, Libs : Library 컴파일 결과로 생성되는 h와 lib 파일들 저장\n\n\nResources : Assets 폴더로 이미지, 사운드, 데이터파일 등을 저장\nBinaries : 프로젝트의 최종 결과물 (exe 파일)\n\nApplication Project\n\nApplication 프로젝트의 Output과 Intermediate의 Directory 설정을 위 이미지에 같이 설정하면 작성된 path로 생성되는 파일들을 생성한 폴더로 저장할 수 있게 됩니다.\n\nStatic Library Project\n\nStatic Library 프로젝트의 경우 위의 이미지와 같이 설정하면 생성되는 Lib 파일들이 Libraries/Libs 폴더에 들어가게 됩니다. 이후 필요한 헤더 파일의 경우 Build Event 설정의 Post-Build Event에서 헤더 파일들을 지정한 위치에 복사하도록 copy src dest 명령어를 설정하면 Build 이후 헤더 파일들을 Include 폴더에 복사할 수 있습니다.\n\n위의 command를 사용하면 현재 프로젝트의 모든 헤더 파일들을 설정한 경로로 복사합니다. 이때 하위 폴더 안에 있더라고 복사하도록 설정해주었습니다.\n복사한 헤더 파일을 읽기 전용으로 변경해주는데 해당 라이브러리를 쓰도록 설정한 프로젝트에서 값을 변경하다 실수로 복사한 헤더파일의 코드가 변경되어서 변경사항이 적용되지 않는 불상사를 방지합니다.\n물론 각 프로젝트 별로 Customize할 수 있도록 읽기 버전으로 변경하지 않아도 됩니다.\nStatic Library 사용법\n생성한 Library나 외부 library를 사용하려면 Link를 설정하고 Lib나 dll 파일도 참조해줘야 Library의 헤더 파일을 include해 사용할 수 있습니다.\n\nLibrary의 헤더 파일들을 모아둔 Libraries/Include 폴더의 위치를 추가해줘 library의 헤더 파일들을 include할 수 있도록 합니다.\n\ninclude한 헤더 파일들을 가져오는 게 가능하도록 lib 파일들이 있는 폴더의 위치를 추가해줍니다.\n이렇게 추가한 Library를 사용하기 위해 pch 헤더에서 참조해줍니다.\n\n위와 같이 ifdef로 나눠준 이유는 library의 build 폴더 경로를 설정할 때 Debug과 Release 모드를 따로 만들어 지도록 설정했기 때문입니다.\n\n또는 위의 이미지에 보이는 것과 같이 CV++ Directories의 General 설정에서 Include Directories와 Library Directories에서 설정해도 된다.\n또 다른 가장 쉬운 방법도 있습니다.\n\n여기서 dependency를 설정하면 Project인 Application이 실행되는데 필요한 프로젝트들을 설정해줄 수 있습니다. 자동으로 설정되는 것입니다. (실제로 잘 사용해보지 않아 제대로 확인해보진 않았음)\n각 프로젝트를 우클릭하면 Project Dependencies에서 Dependency를 설정할 수도 있습니다.\n.gitignore 설정\n.vs/\nIntermediate/\nBinaries/\n\ngitignore 파일에 위의 내용을 추가해 용량이 큰 파일과 build시 생성되는 파일들이 github에 올라가지 않도록 설정합니다.\ncreate gitignore사이트에서 참고할 gitignore 설정을 생성해서 봐도 좋을 것 같다."},"content/Study/AI/논문/APT---Adaptive-Pruning-and-Tuning-Pretrained-Language-Models-forEfficient-Training-and-Inference":{"slug":"content/Study/AI/논문/APT---Adaptive-Pruning-and-Tuning-Pretrained-Language-Models-forEfficient-Training-and-Inference","filePath":"content/Study/AI/논문/APT - Adaptive Pruning and Tuning Pretrained Language Models forEfficient Training and Inference.md","title":"APT - Adaptive Pruning and Tuning Pretrained Language Models forEfficient Training and Inference","links":[],"tags":["AI"],"content":"Abtract\n\nLM의 Fine-tuning과 inference는 비용이 큰 거로 알려져 있어 PeFT로 적은 수의 파라미터를 사용해 훈련할 때 메모리 사용량을 줄이려고 하지만 inference는 향상시키지 못함\nStructured Pruning은 inference를 향상시키지만 가끔 훈련 메모리와 시간을 증가시킴\ntraining과 inference를 둘 다 향상시키기 위해서 APT를 사용\nfine tuning의 초기 단계에서 중요하지 않은 파라미터를 버리면서 빠르고 정확한 수렴을 위해 salient tuning parameter를 동적으로 추가함\n\nbaseline과 비교했을 때 APT는 98% 성능을 유지하면서 60% pruning을 가능하게 했음 (RoBERT와 T5 모델)\nLLAMA 모델은 86.4%의 성능을 유지하면서 70%를 감소\n\n\nAPT는 LM의 fine-tuning 속도를 8배 향상시키고 training에 필요한 메모리를 70% 감소시킴\n\n예시 코드) GitHub - ROIM1998/APT: [ICML’24 Oral] APT: Adaptive Pruning and Tuning Pretrained Language Models for Efficient Training and Inference\n\n\n\nIntroduction\n\n\nAPT adapter를 통해 학습된 LM의 파라미터를 pruning과 fine-tuning을 adaptively하게 진행해 APT는 training과 inference, 둘 모두 향상 시킴\n\nAPT adapter의 input/output dimensions와 rank(r_apt)를 동적으로 adjust(add/reduce)\nadapter dimension을 prune해 차원을 줄이는 것은 고정된 매개변수를 제거해 학습과 추론을 더 빠르고 메모리 효율적으로 만듬\nadapter ranks는 LM의 성능을 회복시키는데 도움을 줌\n\n\n반면, LoRA는 훈련에는 도움이 되지만 모델 크기를 줄이지 않아 inference엔 도움이 안됨\n\nLoRA는 고정된 파라미터와 평행하게 low-rank 선형 계층을 사용하지만 수렴하는데 시간이 오래 걸림 (메모리 사용량 감소)\nstructured pruning은 layer을 없애기에 빠르지만 LM을 재학습하는데 큰 비용과 시간이 듬\n\n\nLoRA와 같은 PEFT와 structured pruning을 함께 사용하면 training과 inference에서 효율을 향상시킬 수 있지만 한계가 있음\n\n눈에 띄는 성능 저하와 추가적인 훈련 비용이 필요\n\n\n\n\n이 논문에서는 PEFT와 structured pruning의 장점을 합쳐 fine-tuning과 inference를 더 효율적이게 할 수 있게 함\n논문에서는 사전 학습된 LM의 파라미터가 일반적인 지식을 가지지만, 그것이 하위 작업(downstream tasks)에 얼마나 중요한지는 다르다고 주장\n\n즉, 모든 파라미터가 동일하게 중요한 것은 아니란 것\nLM의 지식이 특정 작업이나 문제에서는 더 중요하게 작용하고, 다른 작업에서는 덜 중요할 수 있다는 의미\n그래서, 초기 학습 단계에서 fine-tuning 작업과 관련이 없는 파라미터들을 제거해 성능은 유지하면서 모델을 더 간소화하고 효율적으로 만들 수 있음\n\nAPT 매커니즘\n\nAPT는 outlier를 고려하는 salience(중요도) 점수 계산 함수를 통해 pruning mask를 학습하며, 이를 통해 관련 없는 LM 파라미터 블록을 제거\n\noutlier를 고려해 중요도를 평가\n\n\n또한, fine-tuning 중에는 조정이 필요한 layer의 중요도에 따라 더 많은 tuning 파라미터를 추가 (성능 향상)\n\n단순히 파라미터를 줄이지 않고 특정 작업에 중요한 layer의 경우 필요한 파라미터를 추가로 할당해 성능을 최적화\n\n\nteacher와 student 파라미터를 공유하는 self-distributed technique을 통해 효율적으로 계산\n\n즉, APT는 모델의 크기를 줄이면서도 작업에 필요한 부분에는 더 많은 자원을 할당하여 성능을 유지하거나 개선하려는 방법\nRelated Works\n\nPEFT\n\n적은 파라미터만 선택하거나 LoRA와 같은 방법으로 Layer를 추가해 학습의 효율을 늘림\nAdaLoRA는 동적으로 파라미터를 조정하지만 추론 효율은 향상시키지 못함\n\n\nModel Compression\n\n양자화 및 pruning으로 추론 효율성을 향상시키지만 특정 프레임워크/하드웨어 지원이 필요해 제한된 사용\n추가적인 재학습을 통해 훈련 비용이 필요\n\n\n두 방법을 결합\n\ntraining과 inference에서 메모리와 효율이 상승하지만 성능 하락이 심함\n\n\n\n문제 정의\n목표 : 사전 학습된 LM의 성능을 유지하면서 training과 inference의 효율을 향상시키는 것\n\n직관적으로 적은 파라미터만 tuning하면 필요한 훈련 메모리가 작고 시간도 짧음\n파라미터가 적은 모델은 inference할 때 메모리도 적게 필요하고 빠르지만 성능이 안좋음\n\n수학적으로 문제 정의\n\n작업 손실 L을 최소화하면서, 전체 언어 모델(LM)의 파라미터 크기 \\Theta가 T번의 학습 단계 후에 목표 희소성(Target Sparsity, 전체 파라미터 중 pruning된 파라미터 비율) γT​ 도달하도록 제약 조건을 충족\n\n\n작업 손실 L 최소화\n\nL은 미세 조정(fine-tuning) 과정에서 모델이 특정 작업(예: 텍스트 생성, 분류 등)을 수행할 때 발생하는 손실 값입니다.\n목표는 모델의 손실 L을 최소화하는 것입니다. 즉, 모델 성능이 최대한 유지되거나 개선되도록 하는 것이 목표입니다.\n\n\n제약 조건: 목표 희소성 γT\n\n모델의 전체 매개변수 Θ 중 일부를 가지치기(pruning)하여 제거합니다.\n목표 희소성 γT\\gamma_TγT​는 가지치기된 매개변수의 비율을 나타내며, 예를 들어 γT=0.5라면 전체 매개변수의 50%를 제거하는 것입니다.\n이 값이 높을수록 메모리 사용량을 줄어들지만 성능이 하락\n\n\n학습 단계 T\n\n모델은 T번의 학습 단계를 거칩니다. T가 끝났을 때 모델이 γT에 도달해야 합니다. 즉, 학습이 진행되는 동안 점진적으로 매개변수를 줄여가며 목표 희소성을 달성해야 한다는 뜻입니다.\n\n\n\n제약 조건 :매 training step마다 LM의 sparsity가 γT 이상으로 유지되고 tuning 파라미터의 개수는 ∆t 이하로 유지\n\n이를 유지하기 위해 pruning mask (Mt) 와 tuning rank (Rt) 을 Control\narg\\min_{Θ_T, M_T} \\frac{1}{|D|} \\sum_{x,y \\in D} L(x, y | Θ_T, M_T)\n 1 - \\frac{C(Θ_t, M_t)}{C(Θ_0, M_0)} \\geq γ_t, \\delta(Θ_t, M_t, R_t) \\leq ∆_t, $$$$  \\forall t \\in \\{0, 1, \\ldots, T\\}.\nx = inputs, y = labels, D = task Dataset, C  = LM의 총 파라미터 수, δ = LM의 tuning 파라미터 수, t = 현재 학습 단계, T = 전체 학습 단계\n\nAdaptive Pruning and Tuning (APT)\n\nfine-tuning 과정에서 진행\n\n초기 학습 단계에서 Pruning\n\n학습 초기 단계에서 LM의 파라미터를 Prune해 희소성 γT을 증가시키고, 학습 비용을 줄임\nsalience scoring function으로 prune\n\n\ntuning 파라미터 수 제한\n\nPruning 과정에서도 ∆t ≪ C(Θt, Mt)가 되도록 제한해, 학습 과정에서 과도하게 많은 파라미터를 조정하는 일이 없도록 함\n학습 시간이 길어지는 것을 방지하고, 효율성을 높이기 위한 방법\n\n\ntuning 파라미터를 초기 학습 단계에 추가해 학습 성능 하락을 방지\n\n동적으로 파라미터를 추가하면 LM의 수렴을 가속화하고 성능을 유지할 수 있음\nSalient layer에서 파라미터 추가\n\n\n\nAPT adapter\n\nLoRA위에 APT adapter를 구축하지만 동적 pruning과 tuning을 지원하는게 다른점\nfine-tuning 과정 동안 APT adapter가 input X ∈ R^{di}를 output H_{apt}(X) ∈ R^{do}로 project할 때, binary pruning masks (input = m_i ∈ R^{di}, output = m_o ∈ R^{do})와 dynamic rank (r_{apt})를 APT Adapter 안에 설계해 total &amp; tuning 파라미터를 control할 수 있도록 함\n\n구체적으로 tuning 파라미터 W_A ∈ R^{r_{apt}×d_i}와 W_B ∈ R^{d_o×r_{apt}} 를 사용해 APT adapter H_{apt}는 다음과 같이 표시H_{apt}(X) = m_o \\circ (W + s \\cdot W_B W_A)X \\circ m_i \\quad \n\ns = constant scaling factor(LoRA의 구현 따라 상수 scaling factor), \\circ = Mask와 corresponding matrices(해당 행렬)간의 Hadamard 곱\nmultiplying mask가 0으로 설정되면 parameter block이 prune되고 1로 설정되면 유지\n\n\n\n\nfine-tuning 과정 중 가중치 행렬 W_B와 W_A에 대해 r_{apt}를 동적으로 증가\n\n동적으로 조정하므로 LoRA보다 효율적일 수 있음\n\n\n\nTransformer와 FFN\n\nTransformer 기반 모델의 경우 APT adapter를 queries와 values에 추가 (multi-head attention layer, MHA)\n빠른 수렴을 위해 작은 모델을 학습할 땐 feed-forward network (FFN)에도 APT adapter를 추가했음\n\nRoBERTa나 T5 모델\n\n\n이 경우 m_i는 transformer의 hidden dimension를 prune하고 m_o는 MHA의 attention heads와 FFN의 내부 뉴런을 prune함\n\n이렇게 APT adapter는 pruning mask를 학습하고 ranks를 동적으로 조정해 tuning 파라미터가 성능을 유지하고 LM의 전체적인 파라미터 수를 줄여 training과 inference를 효율적으로 할 수 있게 함\nLow-cost Adaptive LM Pruning (A_P)\n\nAPT adapter가 LM의 training과 inference의 효율을 높이기위해 LM 파라미터를 fine-tuning 시작부터 adaptively prune함\n\n문제 : prune할 파라미터를 어떻게 찾는가?\n\nt &lt;&lt; T인 초기 학습 단계 때 특정 작업에 대해 파라미터 block의 outlier-aware salience score를 계산\n이후에 fast-search algorithm을 사용해 prune할 파라미터를 찾아 binary pruning mast를 갱신\n\nOutlier-aware salience scoring of LM parameters\n\ntuning &amp; frozen 파라미터를 모두 고려하는 outlier-aware salience score를 계산하는것이 핵심\nsalience는 파라미터의 가중치-기울기 production(곱셈) 크기(Magnitude)로 정의 됨 S(W_{i,j}) = |W_{i,j} \\cdot \\frac{\\partial L}{\\partial W_{i,j}}| \\quad \n하지만 frozen weight의 기울기는 PEFT에선 접근할 수 없으므로 활성화 값과 그에 대한 기울기의 곱의 크기로 중요도를 계산함\n\n활성화 값(the magnitude of the product of activations) : 신경망에서 각 layer의 출력 값\n기울기(gradient) : 활성화 값에 대해 계산된 기울기\n곱의 크기를 사용하여 중요도를 계산하는 이유는, 활성화 값과 그에 대한 그래디언트가 곱해지면 해당 값이 얼마나 중요한지에 대한 정보를 나타낼 수 있기 때문\nactivation(활성화 값)과 gradients(기울기)를 곱하기전에 배치 단위로 더해 메모리 사용을 줄임\n\n\n\n반면 block outlier의 파라미터는 task-specific 능력에서 중요한 역할을 하며 이전의 양자화 방법들에서 제안되었음\n\noutlier 파라미터에 의해 발생하는 이런 효과는 salience(중요도)가 block level에서 측정되면 평균화될 것임\npruning된 LM에 더 많은 outlier 파라미터를 유지하려면 위의 salience 점수와 활성화의 첨도(kurtosis)를 결합함\n\n그래서 supervised finetuning dataset D_t가 주어지면, outlier-aware salience score \\hat{S} 는 다음과 같이 정의됨\neS(W_{:,j}) = \\sum_{(x,y) \\in D_t} X_i \\left| \\frac{\\partial L(x, y | \\Theta_t, M_t)}{\\partial H_{j,i}} \\right| \\cdot \\sum_{(x,y) \\in D_t} X_i \\left| H_{j,i} \\right| $$$$ \\hat{S}(W_{:,j}) = eS(W_{:,j}) + \\left( Kurt(O_{j,:}) \\right)^{\\frac{1}{2}} \n\nH = LM의 activations 값, Kurt(\\cdot) = Kurtosis, O_{:,j} = W_{:,j} \\circ X^T_{j,:} = activation\n논문의 Appendix B를 보기\n\nEfficient search of LM block parameters\n\nsalience score를 계산했다면 다음으로는 LM sparsity를 \\gamma_t 이상으로 증가시키기 위해 binary pruning mask을 학습하는 단계를 진행\n직관적으로 덜 중요한 salience score를 가진 block을 prune해야 함\n\n이는 latency-saliency knapsack 문제로 공식화됨\n\n\nn_L transformer layers를 가진 LM의 경우, layer i는 n^h_i MHA heads와 n^f_i FFN neurons를 가지고 모든 transformer layers의 hidden dimension sizes는 d_m이고 근사화된 LM 파라미터 수는 다음 수식과 같음 C(\\Theta_t; M_t) \\approx d_m n_L \\sum_{i=1}^{n_L} \\left( 4 n_i^h \\cdot d_h + 2 n_i^f \\right) \n\nd_h = MHA head 당 dimension\n\n\n문제 정의에서 정의한 제약을 유지하기 위해서 MHA heads, FFN neurons와 model hidden dimension을 동시에 pruning해 n_i^h, n_i^f, d_m를 줄임\n\n따라서, 가장 먼저 salience를 파라미터의 수로 나눈 값으로 block을 정렬함\nparameter size는 block의 quantity에 따라 증가하므로 binary search를 사용해 sparsity constraint \\gamma_t에 따라 유지될 상위 salient block을 선택해 제약을 만족\n자세한 건 논문의 Appendix C를 보기\n\n\n\nAdaptive and Efficient LM Tuning (A_T)\n\nPEFT로 fine-tune pruned하면서 성능이 하락한 걸 동적으로 tuning parameters를 추가해 성능을 향상\ntuning parameters를 추가하는건 메모리를 더 사용하는 것이므로 task-sensitive APT adapters에만 추가하는 방식으로 통제\n\n\n각 APT adapter의 중요도를 결정하기 위해 salience score를 계산\nsalience를 기준으로 정렬한 다음 상위 절반의 APT adapters를 선택해 r_{apt}를 증가시켜 parameters를 추가\n\nSalience scoring of APT adapter\n\ntuning parameter의 기울기 정보가 layer salience를 결정할 때 사용하므로, Outlier-aware salience scoring of LM parameters에서 말한 첫 번째 방정식으로 각 tuning parameters의 salience를 계산할 수 있음\nAPT adapter의 salience를 W_B에 있는 parameter salience의 합으로 정의 I(H_{apt}) = \\sum_{i,j} S(W_{B,i,j})\n계산한 각 APT adapter의 I(H_{apt})로 새로운 tuning parameter를 어디에 추가할지 결정 가능\n\nDynamically adding APT adapter parmeters to recover task performance\n\nAPT adapter의 중요도가 I(H_{apt})로 계산되면, adaptive tuning은 다음으로 budget ∆t에 따라 salient tuning layer의 ranks (r_{apt} ∈ R_t)를 증가시켜 tuning parameter를 추가\n\n\n모든 tuning layers을 I(H_{apt})을 기준으로 정렬하고 상위 절반 salient의 rank를 선형적(linearly)으로 증가\n\ntuning parameter를  \\Delta_t에서 \\Delta_t&#039;로 증가시킬 때, salient layer의 rank는 r_{apt}에서 r&#039;_{apt} = \\lfloor r_{apt} \\cdot \\frac{\\Delta_t&#039;}{\\Delta_t} \\rfloor로 변경됨\n\n\\lfloor \\cdot \\rfloor = floor 연산\n\n\n\n\ntraining stability를 위해 parameter를 추가하고 W_B \\in \\mathbb{R}^{d_o \\times r_{apt}}, W_A \\in \\mathbb{R}^{r_{apt} \\times d_i}를 W&#039;_B \\in \\mathbb{R}^{d_o \\times r&#039;_{apt}}, W&#039;_A \\in \\mathbb{R}^{r&#039;_{apt} \\times d_i}로 변환할 때, W_A에는 random Gaussian initialized parameters N(0, \\sigma^2)을 concat하고 W_B에는 0을 연결해서 새로운 paramter가 추가되기 전후에 layer의 출력이 변하지 않도록 함\n\n이는 LoRA의 초기화와 동일\n\n\n\nEfficient Self-Knowledge Distillation\n\nknowledge distillation 없이 training pruned하면 end-task 성능이 상당히 하락하기에 knowledge distillation을 사용\n기존 방식은 fully trained teach model을 student와 함께 GPU에 넣어줘야 하므로 메모리와 training time이 많이 필요했음\n이를 방지하기 위해 fine-tuning 과정동안 tuning student layers를 teachers로 duplicate(복제)해 전체적인 training time을 줄임\nfrozen parameters는 student와 teacher 모델이 공유해 메모리 사용량을 줄임\n기존의 CoFi에서의 distillation objective를 수정한 수식 L = \\mu L_{\\text{distill}} + (1 - \\mu)L_{f t} $$$$ L_{\\text{layer}} = \\sum_{i=1}^T MSE(Tr(H_{\\phi(i)}^s), H_i^t) \n\n\\mu = distillation 과정에서 0에서 1로 선형적(linearly) 변하는 값으로 pre-pruned model이 training data에 잘 맞도록 유도\nL_{distill} = CoFi의 distillation objective, L_{ft} = supervised fine-tuning objective, T = block-wise randomly sampled teacher layers\n\\phi(·) = teacher-student layer-mapping function (teacher layer를 가장 가까운 non-pruned student layer에 matching하기 위함)\nTr = layer transformation을 위한 tunable LoRA layer (matrix I로 초기화)\n더 자세한건 논문의 Appendix A를 참고\n\n\n\n실험\n\n\nResult\n\n제한 사항 및 추가 논의\n1. 성능 격차: 대형 LM에서 가지치기를 할 때, 메모리 소비를 줄이기 위해 증류 없는 설정을 사용했기 때문에 성능 격차가 발생할 수 있습니다. 이를 개선하기 위해 메모리 효율적인 증류와 매개변수 공유 전략이 필요합니다.\n2. 하드웨어 최적화: Ampere 아키텍처 GPU의 특성을 활용하여, 특정 레이어 차원을 최적화하면 더 나은 속도 향상을 얻을 수 있습니다.\n3. 훈련 안정성: 매개변수의 동적 조정으로 인해 훈련이 불안정할 수 있으며, 옵티마이저를 재설정하는 전략이 필요하지만, 이는 불안정성을 초래할 수 있습니다.\n\n\n교사 체크포인트: 훈련 중 교사 체크포인트의 선택 시점이 모델 성능에 영향을 미치며, 적절한 체크포인트 선택이 중요합니다.\n\n\n비선형 어댑터: 비선형 어댑터가 성능 회복에 더 나은 성과를 낼 수 있는지에 대한 가능성을 탐구하고 있으며, 다양한 어댑터를 활용한 적응이 더 잘 탐구될 수 있습니다.\n\n"},"content/Study/AI/논문/SALMONN":{"slug":"content/Study/AI/논문/SALMONN","filePath":"content/Study/AI/논문/SALMONN.md","title":"SALMONN","links":["Cross-Attention","LoRA","Few-Shot-Activation-Tuning"],"tags":["AI"],"content":"모델의 목표\n\nLLM에 일반적인 청각 능력을 부여한 멀티모달\n\n기존에는 특정 작업에 특화된 모델들이 사용됬지만 좀 더 범용적인 모델을 위해 개발\n\n\n이 논문의 도전 과제\n\n서로 다른 오디오 작업을 하나의 모델에서 통합적으로 처리\n\nex) 음성 인식, 음악 설명, 감정 인식 등\n\n\n새로운 오디오 작업이나 데이터에 대한 적응력 향상\n\n처음보는 데이터를 처리할 수 있도록\n\n\n다중 모달(텍스트 + 오디오) 데이터를 동시에 이해할 수 있는 능력\n\n\n\n모델의 구조\n두 가지 주요 컴포넌트로 구성\n\nText LLM\n\n사전 학습된 텍스트 기반 LLM(GPT 계열) 사용\nAudio Encoder에서 추출된 정보를 바탕으로 텍스트 형식의 답변이나 설명을 생성\n\n\nAudio Encoder\n\n음성 및 오디오 데이터를 Vector 표현으로 변환하는 모듈 (다양한 청각 정보를 처리)\n\n입력 Audio를 먼저 Token화 진행\n\n\n오디오 신호에서 중요한 정보를 추출해 LLM에 입력\n기존의 Whisper 모델과 같은 강력한 음성 Encoder 활용 가능\nSpeech audio와 Non-Speed Audio 둘 모두 좋은 성능을 내기 위해 dual encoder structure를 사용\n\nWhisper speech 모델(Speech)과 BEATs audio(Non-Speech) encoder 사용\n출력 특성이 동기화되고 결합\n\n\n두 Encoders가 동일한 출력 frame rate인 50Hz을 가지므로  Z = Concat(Encoder_{whisper}(X), Encoder_{beats}(X)))\n\nX = 가변 길이 audio 입력 sequence, Z = T 프레임을 가진 Encoder 출력 Sequence\n\n\n\n\n멀티모달 연결 (Multi-Modal Fusion)\n\n오디오와 텍스트 데이터를 통합해 하나의 일관된 표현을 생성\n이 과정에서 오디오 정보를 테스트 기반의 이해로 변환\n\n\n\n\n오디오 데이터는 이 Encoder를 통해 특징이 추출되며 LLM은 이를 바탕으로 의미를 이해하고 응답\n\n\nWindow-level Q-Former\n\nwindow-level query Transformer\nQ-Former는 보통 LLM과 다른 입력(image 등)을 연결해주는 새로운 Transformer 방식\n\n간단한 Transformer 구조\n\n\n즉, 서로 다른 데이터를 align 해주는 단계\n오디오 데이터를 처리할 때 인코더가 생성하는 가변 길이 출력 시퀀스를 여러 개의 증강된 Audio Token으로 바꿔 Vicuna LLM의 입력으로 사용할 수 있게 해주는 연결 모듈로 사용\n출력으로 text instruction promp과 Audio Encoder 출력을 통합해 LoRA Adapter와 LLM에 입력으로 사용\n\n\n핵심 개념\n기본 Q-Former\n\n보통 고정된 길이의 Input Token만 사용 (ex: Image)\n\nAudio 데이터를 작은 조각(Window)로 나누고 각 조각을 이미지처럼 처리해 token으로 변환해 가변적인 오디오를 처리\n\n\nImage Encoder의 출력을 고정된 개수의 텍스트 입력 토큰으로 변환하기 위해 자주 사용됨\n하지만 오디오 입력은 길이가 가변적이기에 수정이 필요\n구조 :\n\n이미지 입력 Z1을 고정된 개수 N의 학습 가능한 쿼리 Q를 사용해 H1이라는 텍스트 토큰으로 변환\nQ-Former Block은 Transformer decoder block과 비슷하지만 두 가지 차이점이 존재\n\n첫 블록에서 고정된 학습 가능한 쿼리 Q를 사용\nself-attention 레이어에서 causal mask 제거\n\n\n\n\n이 구조를 통해 쿼리 Q가 서로 먼저 침조한 후, 입력 이미지 Z1과 Cross-Attention으로 상호작용\n\n오디오 입력 처리\n\n오디오 입력 Z는 길이가 가변적이므로 직접 텍스트 토큰으로 변환하기가 어려움\n이를 해결하기 위해 입력 Z를 길이 L의 윈도우로 나누고, 마지막 윈도우는 0으로 Padding\n이렇게 나뉜 window의 Encoder 출력 frame을 이미지 처럼 취급해 Window 수준에서 Q-Former을 사용해 토큰 H로 변환\n최종 텍스트 Token Sequence인 H는 총 [T/L] x N개의 텍스트 토큰을 포함\n\nT = Audio 전체 길이\n\n\n\nQ-Former을 사용해 dual Audio Encoder인 Whisper speech encoder와 BEATs audio encoder의 출력 Token을 연결해 결합\n이는 증강된 오디오 토큰으로 LLM의 입력 공간과 align됨\n(두 Audio Encoder는 Freeze하고 Q-Former만 학습, 즉 쿼리 Q를 학습시킴)\nLoRA\n\nVicuna에 적용되 Vicuna의 입력 공간과 출력 공간을 일치시키는 Cross-Modal Adapter로 사용되며, 성능을 향상시킴\n\nCross-Modal : 서로 다른 형태의 데이터를 다룰 수 있게 만든다는 의미\n\n\n즉, LoRA로 LLM 모델의 입력과 Q-Former의 출력이 서로 잘 맞도록 조정하는 역할을 수행\n훈련을 최적화하는 역할도 수행\n\nLLM을 Freeze하고 LoRA Adapter만 훈련\nself-attention layer에서 Querry와 Value 가중치 행렬에 적용\n\n\n\n훈련 및 학습 방법\n모델은 다양한 오디오 Task에서 학습되었음\n\n음성 인식(ASR) : 음성을 텍스트로 변환\n음성 번역 : 다른 언어로 음성 데이터를 번역\n질의응답: 오디오 기반 질의에 대한 응답\n음악 및 오디오 캡셔닝 : 음악이나 일반 오디오에 대한 설명 생성\n화자 검증 및 감정 인식 : 특정 화자의 확인 및 감정 상태 감지\n\n훈련되지 않은 작업에 대한 일반화 능력을 높이기 위해 Few-Shot Activation Tuning 기법을 사용\n\n이는 모델이 적은 데이터로도 새로운 작업에 적응하도록 도와줌\n\n학습 방법\n3가지 단계로 나눠서 학습\n1. Pre-training State\n\n사전 학습된 LLM &amp; Audio Encoders와 랜덤값으로 초기화된 Q-Former(Connection Module) &amp; LoRA(Adaptor)의 파라미터들 사이의 차이를 줄이기 위한 학습 단계\n\n많은 양의 오디오 데이터를 사용해 window-level Q-Former와 LoRA를 사전 학습 진행\n\n\n이 작업엔 speech와 non-speech 오디오 내용에 대한 주요 정보를 포함하고 있으며, 복잡한 추론과 이해를 요구하지 않기 때문에 audio와 texture간의 alignment(연결, 매핑) 품질을 높이는데 도움이 됨\n\n방대한 양의 오디오-텍스트 훈련 세트를 사용해서 훈련을 진행\n2. Instruction Tuning Stage\n\n\nAudio-Text Instruction Tuning\n\nNLP나 Vision-Language 모델에서처럼 Audio와 텍스트를 함께 학습하는 방식\n이 단계에서 음성 인식, Audio 이벤트 감지, Music Task 같은 다양한 작업을 학습\n\n\nAudio Data와 연결된 Text를 기반으로 모델이 이해할 수 있는 명령어를 생성해 학습에 사용\n\n여러 Task를 포함하며 질문이 Text Caption Labels을 기반으로 GPT를 사용해 생성되며, 모델은 일반 오디오 입력과 질문이 있는 Text prompt를 기반으로 답변을 제공해야 됨\n\n위의 표가 이 단계에서 사용되는 데이터\nTask : ASR(자동 음성 인식), 자동 음성 번역(AST), AAC(오디오 설명 생성), 전화 인식(PR), 감정 인식(ER), 음악 캡션 생성(MC), 중첩 음성 인식(OSR), 화자 인증(SV), 성별 인식(GR), 음성 질문 응답(SQA), 오디오 질문 응답(AQA), 음악 질문 응답(MQA) 등\n\nTask Over-fitting 문제\n\n위의 두 단계만으로 경쟁력있는 결과를 생성할 수 있지만 훈련되지 않은 작업을 수행하는 능력이 거의 없거나 이상한 응답을 생성하는 경우가 발생\n\n이 현상을 task over-fitting이라 부름\n\n\ntask over-fitting의 두 가지 이유\n\nLLM의 훈련에 사용되는 text-only data와 비교해서 cross-modal instruction tuning에 사용된 prompts가 너무 간단해 생성된 응답이 복잡하고 다양하지 않음\nInstruction Tuning에 포함된 일부 작업(특히 음성 인식, Audio Captioning)이 다른 작업들(speech &amp; audio 질의응답) 보다 결정론적인 출력을 가짐\n\n결정론적인 출력(Deterministic Output) : 동일한 입력이 주어지면 항상 동일한 출력값이 나옴\n\n\n\n\n이 두 가지 이유가 결합되어서 일반화 성능이 떨어지게 되고 훈련되지 않은 Cross-modal task에 방해됨\nTest시 새로운 명령 prompt I에 대해 주어진 테스트 입력 X의 response text sequence \\widehat{Y}는 다음과 같이 생성되고 이를 훈련동안 maximise해야됨  \\widehat{Y} = \\arg \\max Y P_{\\wedge} (Y|X, I)\n모델이 훈련에서 제한된 텍스트 response만 보았기 때문에, 이 확률은 일부 작업에 편향됨\n\n자동 음성 인식(ASR) 및 자동 오디오 캡셔닝(AAC) 작업 등\n\n\n\n\n\n3. Activation Tuning Stage:\n\ntask over-fitting을 해결하기 위한 효과적인 접근 방식\n모델을 더 길고 다양한 응답을 가진 task에서 fine-tuning하는 방법\n\ntask : Audio-information-based question answering, storytelling 작업 등\n\n\n이런 task에 대한 훈련 데이터 pair는 audio-text 쌍으로 사람이나 LLM에 의해 생성합\n\n훈련 데이터 pair : test-speech recognition, text-audio and music caption data\n\n\nSALMONN에선 단순히 LoRA adaptor의 scaling factor를 줄여서 zero-shot instructions에 대해 더 길고 다양한 응답을 생성할 수 있게함\n\n이는 훈련에서 Q-Former와 LoRA로만 업데이트되기에 확률을 regulaization하는 대안적인 방법\nLoRA adaptor의 scaling factor를 줄이면 질문 응답 및 스토리텔링 능력을 활성화하고 길고 다양한 응답을 생성 가능하지만 훈련된 task에 대한 결과의 품질은 저하됨\n\n\n응답 결과의 품질 저하를 피하고 길고 다양한 응답을 생성할 수 있도록 LoRA scaling factor의 강도를 낮춰서 적용\n\nAudio Clip을 기반으로 SALMONN으로 작성된 12개의 stories가 사용됨.\n그 후 모델은 12단계동안 teacher-forcing-based-cross-entropy training으로 학습되며, 각 단계(step)에서는 오직 하나의 story sample만 사용되고 이는 SAMOLNN의 cross-modal의 emergent abilities를 활성화\n\nemergent abilities : 훈련되지 않았지만 모델이 방대한 양의 데이터를 학습해 새로운 특성을 가져 처음보는 데이터에 대해서도 좋은 결과를 내는 것\n\n모델의 성능\n단일 Task 특화 모델들이 처리하기 어려운 다양한 작업에서 좋은 성능을 보여줌\n\n음성 기반 slot filling\n훈련되지 않은 언어의 음성 번역\n오디오 기반 스토리텔링 생성\n복합적 오디오 공동 추론\n\n모델의 장점\n\n오디오 및 텍스트 데이터의 통합적 이해\n훈련되지 않은 새롱누 작업에 적응 가능한 일반화 능력\n\n모델의 단점\n\n모델 훈련과 추론에 많은 컴퓨팅 자원이 필요\n\n대규모 데이터 및 계산 능력\n\n\n복잡한 오디오 데이터 처리의 어려움\n\nex) 배경 소음이 있는 상황에서는 정확도가 떨어질 수 있음\n(GPT 답이라 부정확할수도?)\n\n\n"},"content/index":{"slug":"content/index","filePath":"content/index.md","title":"JEngine Blog","links":["content/Projects/JEngine---DX12/JEngine-Project"],"tags":["home","welcome"],"content":"JEngine 블로그에 오신 것을 환영합니다! 🚀\n이곳은 게임 엔진 개발과 컴퓨터 공학 관련 노트를 공유하는 공간입니다.\n주요 카테고리\n📚 Study\n\n인공지능 관련 학습\n알고리즘 연구\nGPU 프로그래밍\n자료구조\n게임 엔진 개발\n게임 수학\n컴퓨터 그래픽스\nUnreal Engine 5\n\n🛠️ Projects\n\nJEngine Project - DirectX12를 이용한 게임 엔진 개발\n\n"},"index":{"slug":"index","filePath":"index.md","title":"JEngine Blog","links":["content/Projects/JEngine---DX12/JEngine-Project"],"tags":["home","welcome"],"content":"JEngine 블로그에 오신 것을 환영합니다! 🚀\n이곳은 게임 엔진 개발과 컴퓨터 공학 관련 노트를 공유하는 공간입니다.\n주요 카테고리\n📚 Study\n\n인공지능 관련 학습\n알고리즘 연구\nGPU 프로그래밍\n자료구조\n게임 엔진 개발\n게임 수학\n컴퓨터 그래픽스\nUnreal Engine 5\n\n🛠️ Projects\n\nJEngine Project - DirectX12를 이용한 게임 엔진 개발\n\n"}}